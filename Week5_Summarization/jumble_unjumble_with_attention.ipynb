{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_files():\n",
    "    if os.path.exists(\"DataSets/Jumble/jumbled.txt\"): os.remove(\"DataSets/Jumble/jumbled.txt\")\n",
    "    if os.path.exists(\"DataSets/Jumble/unjumbled.txt\"): os.remove(\"DataSets/Jumble/unjumbled.txt\")   \n",
    "    f1 = open(\"DataSets/Jumble/jumbled.txt\",\"w\")\n",
    "    f2 = open(\"DataSets/Jumble/unjumbled.txt\",\"w\")\n",
    "    with open(\"DataSets/Jumble/source.txt\",\"r\") as f:\n",
    "        for line in f:\n",
    "            split_line = line.lower().strip().split()\n",
    "            sentence = split_line[1:]\n",
    "            f2.write(' '.join(sentence)+\"\\n\")\n",
    "            random.shuffle(sentence)\n",
    "            f1.write(\" \".join(sentence)+\"\\n\")\n",
    "    f1.close()\n",
    "    f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_of_words():\n",
    "    word_count_dict = {}\n",
    "    with open(\"DataSets/Jumble/jumbled.txt\",\"r\") as f:\n",
    "        for line in f:\n",
    "            words = line.split()\n",
    "            for word in words:\n",
    "                if word in word_count_dict: word_count_dict[word] += 1\n",
    "                else: word_count_dict[word] = 1\n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8918\n"
     ]
    }
   ],
   "source": [
    "word_count_dict = get_count_of_words()\n",
    "print(len(word_count_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3001\n"
     ]
    }
   ],
   "source": [
    "min_word_count = 4\n",
    "count = 0\n",
    "for k,v in word_count_dict.items():\n",
    "    if v > min_word_count: count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_less_frequent_words(filename,word_count_dict,min_word_count,replace_token=\"<unk>\"):\n",
    "    with open(filename,\"r\") as f:\n",
    "        with open(\"DataSets/Jumble/processed_\"+filename.split(\"/\")[-1],\"w\") as f1:\n",
    "            for line in f:\n",
    "                words = line.strip().split()\n",
    "                sentence_to_write = []\n",
    "                for word in words:\n",
    "                    if word_count_dict[word] > min_word_count: sentence_to_write.append(word)\n",
    "                    else: sentence_to_write.append(replace_token)\n",
    "                sentence_to_write.append(\"\\n\")\n",
    "                f1.write(\" \".join(sentence_to_write))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_less_frequent_words(\n",
    "    \"DataSets/Jumble/jumbled.txt\",word_count_dict,min_word_count=min_word_count,replace_token=\"<unk>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_less_frequent_words(\n",
    "    \"DataSets/Jumble/unjumbled.txt\",word_count_dict,min_word_count=min_word_count,replace_token=\"<unk>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabBuilder:\n",
    "    def __init__(self,text_corpus,unknown_token=None,pad_token=None,sos_token=None,eos_token=None):\n",
    "        '''\n",
    "        text_corpus = [\n",
    "            sentence_1,  # sentence_1 = \"a yellow car ...\"\n",
    "            sentence_2\n",
    "            ...\n",
    "        ]\n",
    "        '''\n",
    "        self.text_corpus = text_corpus\n",
    "        self.unknown_token = unknown_token or \"<unk>\"\n",
    "        self.pad_token = pad_token or \"<pad>\"\n",
    "        self.sos_token = sos_token or \"<sos>\"\n",
    "        self.eos_token = eos_token or \"<eos>\"\n",
    "        self.word_to_index, self.index_to_word = self.get_vocabs()\n",
    "                        \n",
    "    def get_vocabs(self):\n",
    "        word_to_index = {}\n",
    "        index_count = 0\n",
    "        for sentence in self.text_corpus:\n",
    "            words = sentence.split()\n",
    "            for word in words:\n",
    "                if word not in word_to_index:\n",
    "                    word_to_index[word] = index_count\n",
    "                    index_count += 1\n",
    "        if not self.unknown_token in word_to_index: \n",
    "            word_to_index[self.unknown_token] = index_count\n",
    "            index_count += 1\n",
    "        if not self.pad_token in word_to_index: \n",
    "            word_to_index[self.pad_token] = index_count\n",
    "            index_count += 1\n",
    "        if not self.sos_token in word_to_index: \n",
    "            word_to_index[self.sos_token] = index_count\n",
    "            index_count += 1\n",
    "        if not self.eos_token in word_to_index: \n",
    "            word_to_index[self.eos_token] = index_count\n",
    "            index_count += 1\n",
    "        index_to_word = {v:k for k,v in word_to_index.items()}\n",
    "        return word_to_index, index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeDecode:\n",
    "    def __init__(self,word_to_index,index_to_word,pad_token,unknown_token,smallcase=True):\n",
    "        self.smallcase = smallcase\n",
    "        self.word_to_index = word_to_index\n",
    "        self.index_to_word = index_to_word\n",
    "        self.pad_token = pad_token\n",
    "        self.unknown_token = unknown_token\n",
    "    \n",
    "    def get_encoding(self,sentence):\n",
    "        '''\n",
    "        sentence can be a string, or a list of words\n",
    "        '''\n",
    "        if isinstance(sentence,str): sentence = sentence.split(\" \")\n",
    "        if self.smallcase: sentence =  [word.lower() for word in sentence]\n",
    "        encoded_sentence = []\n",
    "        for word in sentence:\n",
    "            if word in self.word_to_index: encoded_sentence.append(self.word_to_index[word])\n",
    "            else: encoded_sentence.append(self.word_to_index[self.unknown_token])\n",
    "        return encoded_sentence\n",
    "    \n",
    "    def get_decoding(self,encoded_sentence):\n",
    "        '''\n",
    "        encoded_sentence must be a list of vocab indices.\n",
    "        Ex: encoded_sentence = [24,21,4,1,..] \n",
    "        '''\n",
    "        sentence = [self.index_to_word[index] for index in encoded_sentence]\n",
    "        return \" \".join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnjumbleEncoderModel(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,num_lstm_layers,hidden_size,make_bidirectional,debug):\n",
    "        super().__init__()\n",
    "        self.debug = debug\n",
    "        self.bidirectional = make_bidirectional\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.gru = nn.GRU(input_size=embedding_dim,hidden_size=hidden_size,dropout=0.5,\n",
    "                            num_layers=num_lstm_layers,bidirectional=make_bidirectional,batch_first=True)\n",
    "        \n",
    "    def forward(self,x,h):\n",
    "        if self.debug: \n",
    "            print(\"_______________________________\")\n",
    "            print(\"\\t\\tEncoder\\t\\t\")\n",
    "            print(\"_______________________________\")\n",
    "        if self.debug: print(\"Before starting: x Shape:\",x.shape,\"Prev State Shape\",h.shape)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = self.relu(x)\n",
    "        if self.debug: print(\"Embedding, x Shape:\",x.shape)\n",
    "        \n",
    "        op,ht = self.gru(x,h)\n",
    "        if self.debug: print(\"GRU, op Shape:\",op.shape,\"ht shape\",ht.shape)\n",
    "        \n",
    "        if self.bidirectional: \n",
    "            ht_for_decoder = torch.cat((ht[-1],ht[-2]),axis=1)\n",
    "            ht_for_decoder = ht_for_decoder.unsqueeze(0)\n",
    "        else: ht_for_decoder = ht[-1].unsqueeze(0)\n",
    "        if self.debug: print(\"ht for decoder shape\",ht_for_decoder.shape)\n",
    "            \n",
    "        return op,ht,ht_for_decoder\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        first_param = self.num_lstm_layers\n",
    "        if self.bidirectional: first_param *= 2\n",
    "        return torch.zeros(first_param, 1, self.hidden_size)\n",
    "\n",
    "class UnjumbleBahadnauAttention(nn.Module):\n",
    "    def __init__(self,attention_neurons,debug):\n",
    "        super().__init__()\n",
    "        self.debug = debug\n",
    "        self.rnn = nn.RNNCell(input_size=attention_neurons,hidden_size=attention_neurons,bias=False)\n",
    "        self.linear = nn.Linear(in_features = attention_neurons, out_features = 1)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "    \n",
    "    def forward(self,op_from_enoder,st_minus_one_from_decoder):\n",
    "        \n",
    "        # Reshape the op_from_enoder from (batch_size,seq_length,lstm_neurons) to (batch_size*seq_length,lstm_neurons)\n",
    "        # And reshape st_minus_one_from_decoder from (1,batch_size,lstm_neurons) to (batch_size,lstm_neurons)\n",
    "        # And repeat st_minus_one_from_decoder to seq_length times to get (batch_size*seq_length,lstm_neurons)\n",
    "        if self.debug: \n",
    "            print(\"_______________________________\")\n",
    "            print(\"\\t\\tAttention\\t\\t\")\n",
    "            print(\"_______________________________\")\n",
    "        seq_length = op_from_enoder.shape[1]\n",
    "        op_from_enoder = op_from_enoder.reshape(-1,op_from_enoder.shape[2])\n",
    "        st_minus_one_from_decoder = st_minus_one_from_decoder[-1]\n",
    "        st_minus_one_from_decoder = st_minus_one_from_decoder.repeat(seq_length,1)\n",
    "        if self.debug: print(\"Shape of op_from_encoder:\",op_from_enoder.shape,\n",
    "                             \"Shape of st_minus_one_from_decoder:\",st_minus_one_from_decoder.shape)\n",
    "            \n",
    "        rnn_op = self.rnn(op_from_enoder,st_minus_one_from_decoder)\n",
    "        if self.debug: print(\"RNN Cell Op:\",rnn_op.shape)\n",
    "            \n",
    "        linear_op = self.linear(rnn_op)\n",
    "        if self.debug: print(\"Linear Op:\",linear_op.shape)\n",
    "            \n",
    "        softmax_op = self.softmax(linear_op)\n",
    "        if self.debug: print(\"Softmax Op:\",softmax_op.shape)\n",
    "            \n",
    "        ct = torch.sum(torch.mul(op_from_enoder,softmax_op),dim=0).unsqueeze(0)\n",
    "        if self.debug: print(\"Weighted Averaged h vectors:\",ct.shape)\n",
    "        \n",
    "        return ct,softmax_op\n",
    "        \n",
    "\n",
    "class UnjumbleDecoderModel(nn.Module):\n",
    "    def __init__(self,model_attention,vocab_size,embedding_dim,num_lstm_layers,\n",
    "                 hidden_size,make_bidirectional,debug):\n",
    "        super().__init__()\n",
    "        self.debug = debug\n",
    "        self.model_attention = model_attention\n",
    "        self.bidirectional = make_bidirectional\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.gru_input_size = embedding_dim  + hidden_size\n",
    "        self.gru = nn.GRU(input_size=self.gru_input_size,hidden_size=hidden_size,\n",
    "                            num_layers=num_lstm_layers,bidirectional=make_bidirectional,batch_first=True)\n",
    "        self.in_features = hidden_size*2 if make_bidirectional else hidden_size\n",
    "        self.linear = nn.Linear(in_features=self.in_features, out_features=vocab_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self,x,s0_from_encoder,op_from_encoder_for_attn):\n",
    "        if self.debug: \n",
    "            print(\"_______________________________\")\n",
    "            print(\"\\t\\tDecoder\\t\\t\")\n",
    "            print(\"_______________________________\")\n",
    "        if self.debug: print(\"Before starting: x Shape:\",x.shape,\" s0_from_encoder Shape:\",s0_from_encoder.shape)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = self.relu(x)\n",
    "        if self.debug: print(\"Embedding, x Shape:\",x.shape)\n",
    "        \n",
    "        \n",
    "        seq_length = x.shape[1]\n",
    "        if self.debug: print(\"Sequence Length:\",seq_length)\n",
    "        \n",
    "        all_timestep_op = []\n",
    "        for i in range(seq_length):\n",
    "            if i == 0: \n",
    "                ct,softmax_op = self.model_attention(op_from_encoder_for_attn,s0_from_encoder)\n",
    "                concatenated_x = torch.cat((x[0][i].unsqueeze(0),ct),axis=1)\n",
    "                if self.debug: print(\"concatenated_x shape:\",concatenated_x.shape)\n",
    "                gru_op,ht = self.gru(concatenated_x.unsqueeze(0),s0_from_encoder)\n",
    "                \n",
    "            else: \n",
    "                ct,softmax_op = self.model_attention(op_from_encoder_for_attn,ht)\n",
    "                concatenated_x = torch.cat((x[0][i].unsqueeze(0),ct),axis=1)\n",
    "                if self.debug: print(\"concatenated_x shape:\",concatenated_x.shape)\n",
    "                gru_op,ht = self.gru(concatenated_x.unsqueeze(0),ht)\n",
    "            \n",
    "            all_timestep_op.append(gru_op)\n",
    "            if self.debug:\n",
    "                print(\"---------------------------------\")\n",
    "                print(\"GRU_OP:\",gru_op.shape,\"Ht:\",ht.shape)\n",
    "                print(\"---------------------------------\")\n",
    "        \n",
    "        gru_final_op = torch.cat(all_timestep_op,axis=1)\n",
    "        if self.debug: print(\"GRU, Final Shape:\",gru_final_op.shape,\"ht shape\",ht.shape)\n",
    "            \n",
    "        # Resizing caption for Linear Layer\n",
    "        gru_final_op = gru_final_op.reshape(-1,gru_final_op.shape[2])\n",
    "        if self.debug: print(\"Reshaping gru_final_op Shape:\",gru_final_op.shape)\n",
    "        \n",
    "        linear_op = self.linear(gru_final_op)\n",
    "        if self.debug: print(\"Linear linear_op Shape:\",linear_op.shape)\n",
    "        \n",
    "        op = self.log_softmax(linear_op)\n",
    "        if self.debug: print(\"log_softmax op Shape:\",op.shape)\n",
    "            \n",
    "        if self.debug:print(\"_______________________________\\n\\n\")\n",
    "            \n",
    "        return op,ht,softmax_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40460 40460 40460\n"
     ]
    }
   ],
   "source": [
    "unknown_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "Xe,Xd,Y = [],[],[]\n",
    "with open(\"DataSets/Jumble/processed_jumbled.txt\",\"r\") as f:\n",
    "    for line in f:\n",
    "        Xe.append(line.strip()+\" \" +eos_token)\n",
    "with open(\"DataSets/Jumble/processed_unjumbled.txt\",\"r\") as f:\n",
    "    for line in f:\n",
    "        Xd.append(sos_token+\" \"+line.strip())\n",
    "        Y.append(line.strip()+\" \" +eos_token)\n",
    "print(len(Xe),len(Xd),len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36414 4046 36414 4046 36414 4046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3005, 3005, 3005, 3005)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr_e, Xval_e, Xtr_d, Xval_d, Ytr, Yval = train_test_split(Xe,Xd,Y,test_size=0.1,random_state=20)\n",
    "print(len(Xtr_e), len(Xval_e), len(Xtr_d), len(Xval_d), len(Ytr), len(Yval))\n",
    "encoder_vocab_builder = VocabBuilder(Xtr_e,unknown_token=unknown_token,pad_token=pad_token,sos_token=sos_token,eos_token=eos_token)\n",
    "decoder_vocab_builder = VocabBuilder(Xtr_d,unknown_token=unknown_token,pad_token=pad_token,sos_token=sos_token,eos_token=eos_token)\n",
    "encoder_wtoi,encoder_itow = encoder_vocab_builder.word_to_index, encoder_vocab_builder.index_to_word\n",
    "decoder_wtoi,decoder_itow = decoder_vocab_builder.word_to_index, decoder_vocab_builder.index_to_word\n",
    "len(encoder_itow),len(encoder_wtoi),len(decoder_wtoi),len(decoder_itow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "hidden_size_encoder = 400\n",
    "hidden_size_decoder = hidden_size_encoder\n",
    "model_encoder = UnjumbleEncoderModel(\n",
    "    vocab_size=len(encoder_wtoi),embedding_dim=300,num_lstm_layers=2,\n",
    "    hidden_size=hidden_size_encoder,make_bidirectional=True,debug=True\n",
    ").to(device)\n",
    "if model_encoder.bidirectional: hidden_size_decoder = 2*hidden_size_encoder\n",
    "model_attention = UnjumbleBahadnauAttention(hidden_size_decoder,debug=True).to(device)\n",
    "model_decoder = UnjumbleDecoderModel(\n",
    "    model_attention = model_attention,\n",
    "    vocab_size=len(encoder_wtoi),embedding_dim=300,num_lstm_layers=1,\n",
    "    hidden_size=hidden_size_decoder,make_bidirectional=False,debug=True\n",
    ").to(device)\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer_encoder = torch.optim.Adam(model_encoder.parameters(),lr=0.003)\n",
    "optimizer_decoder = torch.optim.Adam(model_decoder.parameters(),lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = 6\n",
    "encoder_encode_decode = EncodeDecode(encoder_wtoi,encoder_itow,pad_token,unknown_token)\n",
    "decoder_encode_decode = EncodeDecode(decoder_wtoi,decoder_itow,pad_token,unknown_token)\n",
    "print(Xtr_e[data_index],encoder_encode_decode.get_encoding(Xtr_e[data_index]))\n",
    "print(Xtr_d[data_index],decoder_encode_decode.get_encoding(Xtr_d[data_index]))\n",
    "print(Ytr[data_index],decoder_encode_decode.get_encoding(Ytr[data_index]))\n",
    "\n",
    "init_ht_for_encoder = model_encoder.init_hidden().to(device)\n",
    "model_encoder.train()\n",
    "model_decoder.train()\n",
    "\n",
    "optimizer_encoder.zero_grad()\n",
    "optimizer_decoder.zero_grad()\n",
    "Xe_b = torch.tensor([encoder_encode_decode.get_encoding(Xtr_e[data_index])]).to(device)\n",
    "Xd_b = torch.tensor([decoder_encode_decode.get_encoding(Xtr_d[data_index])]).to(device)\n",
    "Y_b = torch.tensor([decoder_encode_decode.get_encoding(Ytr[data_index])]).to(device)\n",
    "print(Xe_b.shape,Xd_b.shape,Y_b.shape)\n",
    "op_from_encoder,ht,ht_for_decoder = model_encoder(Xe_b,init_ht_for_encoder)\n",
    "op,_,_ = model_decoder(Xd_b,ht_for_decoder,op_from_encoder)\n",
    "ht = ht.detach()\n",
    "loss = loss_fn(op,Y_b.reshape(-1))\n",
    "loss.backward()\n",
    "optimizer_encoder.step()\n",
    "optimizer_decoder.step()\n",
    "\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "optimizer_encoder.zero_grad()\n",
    "optimizer_decoder.zero_grad()\n",
    "Xe_b = torch.tensor([encoder_encode_decode.get_encoding(Xtr_e[data_index+1])]).to(device)\n",
    "Xd_b = torch.tensor([decoder_encode_decode.get_encoding(Xtr_d[data_index+1])]).to(device)\n",
    "Y_b = torch.tensor([decoder_encode_decode.get_encoding(Ytr[data_index+1])]).to(device)\n",
    "print(Xe_b.shape,Xd_b.shape,Y_b.shape)\n",
    "op_from_encoder,ht,ht_for_decoder = model_encoder(Xe_b,ht)\n",
    "op,_,_ = model_decoder(Xd_b,ht_for_decoder,op_from_encoder)\n",
    "ht = ht.detach()\n",
    "loss = loss_fn(op,Y_b.reshape(-1))\n",
    "loss.backward()\n",
    "optimizer_encoder.step()\n",
    "optimizer_decoder.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_encoder,model_decoder,encoder_encode_decode,decoder_itow,decoder_wtoi):\n",
    "    data_index = random.randint(0,100)\n",
    "    Xe_b = torch.tensor([encoder_encode_decode.get_encoding(Xval_e[data_index])]).to(device)\n",
    "    print(Xval_e[data_index],Xe_b)\n",
    "    print(Xval_d[data_index])\n",
    "    \n",
    "    model_encoder.eval()\n",
    "    model_decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        softmax_ops = []\n",
    "        init_ht_for_encoder = model_encoder.init_hidden().to(device)\n",
    "        op_from_encoder,ht,ht_for_decoder = model_encoder(Xe_b,init_ht_for_encoder)\n",
    "        sos_word = torch.tensor([[decoder_wtoi[\"<sos>\"]]]).to(device)\n",
    "        op,ht,softmax_op = model_decoder(sos_word,ht_for_decoder,op_from_encoder)\n",
    "        softmax_ops.append([round(float(el),3) for el in softmax_op.cpu()])\n",
    "        unjumbled_sentence = []\n",
    "        for i in range(25):\n",
    "            predicted_word = torch.argmax(op,axis=1).tolist()\n",
    "#             print(\"Predicted .....................\",predicted_word)\n",
    "            unjumbled_sentence.append(decoder_itow[predicted_word[0]])\n",
    "            if predicted_word[0] == decoder_wtoi[\"<eos>\"]: break\n",
    "            op,ht,softmax_op = model_decoder(torch.tensor([predicted_word]).to(device),ht,op_from_encoder)\n",
    "            softmax_ops.append([round(float(el),3) for el in softmax_op.cpu()])\n",
    "        print(\"_______________________________________\")\n",
    "        print(unjumbled_sentence)\n",
    "        print(\"attention weights\")\n",
    "        df = pd.DataFrame(softmax_ops)\n",
    "        if df.shape[0] == len(unjumbled_sentence):\n",
    "            jumbled_words = Xval_e[data_index].split()\n",
    "            df.columns = jumbled_words\n",
    "            df.index = unjumbled_sentence\n",
    "            plt.figure(figsize=(16,4))\n",
    "            sns.heatmap(df, annot=True)\n",
    "            plt.show()\n",
    "        print(\"_______________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model_encoder,model_decoder,encoder_encode_decode,decoder_itow,decoder_wtoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "hidden_size_encoder = 400\n",
    "hidden_size_decoder = hidden_size_encoder\n",
    "model_encoder = UnjumbleEncoderModel(\n",
    "    vocab_size=len(encoder_wtoi),embedding_dim=300,num_lstm_layers=2,\n",
    "    hidden_size=hidden_size_encoder,make_bidirectional=True,debug=False\n",
    ").to(device)\n",
    "if model_encoder.bidirectional: hidden_size_decoder = 2*hidden_size_encoder\n",
    "model_attention = UnjumbleBahadnauAttention(hidden_size_decoder,debug=False).to(device)\n",
    "model_decoder = UnjumbleDecoderModel(\n",
    "    model_attention = model_attention,\n",
    "    vocab_size=len(encoder_wtoi),embedding_dim=300,num_lstm_layers=1,\n",
    "    hidden_size=hidden_size_decoder,make_bidirectional=False,debug=False\n",
    ").to(device)\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer_encoder = torch.optim.Adam(model_encoder.parameters(),lr=0.0003)\n",
    "optimizer_decoder = torch.optim.Adam(model_decoder.parameters(),lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "for i in range(epochs):\n",
    "    init_ht_for_encoder = model_encoder.init_hidden().to(device)\n",
    "    model_encoder.train()\n",
    "    model_decoder.train()\n",
    "    epoch_loss = 0\n",
    "    for j in range(len(Xtr_e)):\n",
    "        optimizer_encoder.zero_grad()\n",
    "        optimizer_decoder.zero_grad()\n",
    "        Xe_b = torch.tensor([encoder_encode_decode.get_encoding(Xtr_e[j])]).to(device)\n",
    "        Xd_b = torch.tensor([decoder_encode_decode.get_encoding(Xtr_d[j])]).to(device)\n",
    "        Y_b = torch.tensor([decoder_encode_decode.get_encoding(Ytr[j])]).to(device)\n",
    "        op_from_encoder,ht,ht_for_decoder = model_encoder(Xe_b,init_ht_for_encoder)\n",
    "        op,_,_ = model_decoder(Xd_b,ht_for_decoder,op_from_encoder)\n",
    "#         ht = ht.detach()\n",
    "#         init_ht_for_encoder = ht\n",
    "        loss = loss_fn(op,Y_b.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer_encoder.step()\n",
    "        optimizer_decoder.step()\n",
    "        batch_loss = loss.item()\n",
    "        epoch_loss += batch_loss\n",
    "        if j%2000 == 0: print(\"Epoch:\",i,\"Batch:\",j,\"Loss:\",batch_loss)\n",
    "    print(\"______________________________________\")\n",
    "    print(\"Epoch Loss:\",epoch_loss)\n",
    "    predict(model_encoder,model_decoder,encoder_encode_decode,decoder_itow,decoder_wtoi)\n",
    "    print(\"_______________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_whole_val(model_encoder,model_decoder,encoder_encode_decode,decoder_itow,decoder_wtoi):\n",
    "    model_encoder.eval()\n",
    "    model_decoder.eval()\n",
    "    accuracy_tuple_list = []  #[(jumbed_sent,unjumbled_sent,predicted_sent,hard,soft,word_count),...,]\n",
    "    with torch.no_grad():\n",
    "        for data_index in range(len(Xval_e)):\n",
    "            if data_index % 50 == 0: print(data_index,end = ' ')\n",
    "            Xe_b = torch.tensor([encoder_encode_decode.get_encoding(Xval_e[data_index])]).to(device)\n",
    "\n",
    "            init_ht_for_encoder = model_encoder.init_hidden().to(device)\n",
    "            op_from_encoder,ht,ht_for_decoder = model_encoder(Xe_b,init_ht_for_encoder)\n",
    "            sos_word = torch.tensor([[decoder_wtoi[\"<sos>\"]]]).to(device)\n",
    "            op,ht,softmax_op = model_decoder(sos_word,ht_for_decoder,op_from_encoder)\n",
    "            unjumbled_sentence = []\n",
    "            for i in range(25):\n",
    "                predicted_word = torch.argmax(op,axis=1).tolist()\n",
    "                unjumbled_sentence.append(decoder_itow[predicted_word[0]])\n",
    "                if predicted_word[0] == decoder_wtoi[\"<eos>\"]: break\n",
    "                op,ht,softmax_op = model_decoder(torch.tensor([predicted_word]).to(device),ht,op_from_encoder)\n",
    "                \n",
    "            hard_accuracy = 1 if \" \".join(unjumbled_sentence) == Yval[data_index] else 0\n",
    "            word_count = len(set(Yval[data_index].split()))\n",
    "            soft_accuracy = len(set(unjumbled_sentence).intersection(set(Yval[data_index].split())))/word_count\n",
    "            accuracy_tuple_list.append(\n",
    "                (Xval_e[data_index],Yval[data_index],\" \".join(unjumbled_sentence),hard_accuracy,soft_accuracy,word_count)\n",
    "            )\n",
    "    return accuracy_tuple_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tuple_list = predict_on_whole_val(model_encoder,model_decoder,encoder_encode_decode,decoder_itow,decoder_wtoi)\n",
    "df = pd.DataFrame(accuracy_tuple_list)\n",
    "df.columns = [\"jumbled_sent\",\"unjumbled_sent\",\"prediction\",\"hard_accuracy\",\"soft_accuracy\",\"word_count\"]\n",
    "print(df.shape,df['hard_accuracy'].sum())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sum((df['soft_accuracy']*df['word_count']).tolist())\n",
    "b = df['word_count'].sum()\n",
    "a,b,a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['soft_accuracy']==1].shape, df[df['soft_accuracy']==1].shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test(model_encoder_new,model_decoder_new,encoder_encode_decode,decoder_itow,decoder_wtoi):\n",
    "    model_encoder_new.eval()\n",
    "    model_decoder_new.eval()\n",
    "    accuracy_tuple_list = []  #[(jumbed_sent,unjumbled_sent,predicted_sent,hard,soft,word_count),...,]\n",
    "    with torch.no_grad():\n",
    "        for data_index in range(len(Xtest_e)):\n",
    "            if data_index % 50 == 0: print(data_index,end = ' ')\n",
    "            Xe_b = torch.tensor([encoder_encode_decode.get_encoding(Xtest_e[data_index])]).to(device)\n",
    "            init_ht_for_encoder = model_encoder_new.init_hidden().to(device)\n",
    "            op_from_encoder,ht,ht_for_decoder = model_encoder_new(Xe_b,init_ht_for_encoder)\n",
    "            sos_word = torch.tensor([[decoder_wtoi[\"<sos>\"]]]).to(device)\n",
    "            op,ht,softmax_op = model_decoder_new(sos_word,ht_for_decoder,op_from_encoder)\n",
    "            unjumbled_sentence = []\n",
    "            for i in range(25):\n",
    "                predicted_word = torch.argmax(op,axis=1).tolist()\n",
    "                unjumbled_sentence.append(decoder_itow[predicted_word[0]])\n",
    "                if predicted_word[0] == decoder_wtoi[\"<eos>\"]: break\n",
    "                op,ht,softmax_op = model_decoder_new(torch.tensor([predicted_word]).to(device),ht,op_from_encoder)\n",
    "            hard_accuracy = 1 if \" \".join(unjumbled_sentence) == Ytest[data_index] else 0\n",
    "            word_count = len(set(Ytest[data_index].split()))\n",
    "            soft_accuracy = len(set(unjumbled_sentence).intersection(set(Ytest[data_index].split())))/word_count\n",
    "            accuracy_tuple_list.append(\n",
    "                (Xtest_e[data_index],Ytest[data_index],\" \".join(unjumbled_sentence),hard_accuracy,soft_accuracy,word_count)\n",
    "            )\n",
    "    return accuracy_tuple_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_e = [\n",
    "    \"is eating . Nitish apple <eos>\",\n",
    "    \"is city my favorite New York. <eos>\",\n",
    "    \"a a and dog are man woods walking through the . <eos>\"\n",
    "]\n",
    "Ytest = [\n",
    "    \"Nitish is eating apple . <eos>\",\n",
    "    \"New York is my faorite city. <eos>\",\n",
    "    \"a man and a dog are walking through the woods . <eos>\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tuple_list_test = predict_on_test(model_encoder,model_decoder,encoder_encode_decode,decoder_itow,decoder_wtoi)\n",
    "df_test = pd.DataFrame(accuracy_tuple_list_test)\n",
    "df_test.columns = [\"jumbled_sent\",\"unjumbled_sent\",\"prediction\",\"hard_accuracy\",\"soft_accuracy\",\"word_count\"]\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention Model was not required to be saved explicitly as it is a part of the decoder model only.\n",
    "#### Additionally the word_to_index and index_to_word dictionary and get_encoding funtion will be required for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_encoder.state_dict(), \"SavedModels/Jumble/encoder_model.pt\")\n",
    "torch.save(model_attention.state_dict(), \"SavedModels/Jumble/attention_model.pt\")\n",
    "torch.save(model_decoder.state_dict(), \"SavedModels/Jumble/decoder_model.pt\")\n",
    "\n",
    "# torch.save(model_encoder,\"SavedModels/Jumble/encoder_model.pt\")\n",
    "# torch.save(model_attention,\"SavedModels/Jumble/attention_model.pt\")\n",
    "# torch.save(model_decoder,\"SavedModels/Jumble/decoder_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnjumbleDecoderModel(\n",
       "  (model_attention): UnjumbleBahadnauAttention(\n",
       "    (rnn): RNNCell(800, 800, bias=False)\n",
       "    (linear): Linear(in_features=800, out_features=1, bias=True)\n",
       "    (softmax): Softmax(dim=0)\n",
       "  )\n",
       "  (embedding): Embedding(3005, 300)\n",
       "  (relu): ReLU()\n",
       "  (gru): GRU(1100, 800, batch_first=True)\n",
       "  (linear): Linear(in_features=800, out_features=3005, bias=True)\n",
       "  (log_softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "hidden_size_encoder = 400\n",
    "encoder_encode_decode = EncodeDecode(encoder_wtoi,encoder_itow,pad_token,unknown_token)\n",
    "decoder_encode_decode = EncodeDecode(decoder_wtoi,decoder_itow,pad_token,unknown_token)\n",
    "loaded_encoder_model = UnjumbleEncoderModel(\n",
    "    vocab_size=len(encoder_wtoi),embedding_dim=300,num_lstm_layers=2,\n",
    "    hidden_size=hidden_size_encoder,make_bidirectional=True,debug=False\n",
    ").to(device)\n",
    "loaded_encoder_model.load_state_dict(torch.load(\"SavedModels/Jumble/encoder_model.pt\"))\n",
    "loaded_encoder_model.eval()\n",
    "\n",
    "if loaded_encoder_model.bidirectional: hidden_size_decoder = 2*hidden_size_encoder\n",
    "loaded_attention_model = UnjumbleBahadnauAttention(hidden_size_decoder,debug=False).to(device)\n",
    "loaded_attention_model.load_state_dict(torch.load(\"SavedModels/Jumble/attention_model.pt\"))\n",
    "loaded_attention_model.eval()\n",
    "\n",
    "loaded_decoder_model = UnjumbleDecoderModel(model_attention = loaded_attention_model,\n",
    "    vocab_size=len(encoder_wtoi),embedding_dim=300,num_lstm_layers=1,\n",
    "    hidden_size=hidden_size_decoder,make_bidirectional=False,debug=False\n",
    ").to(device)\n",
    "loaded_decoder_model.load_state_dict(torch.load(\"SavedModels/Jumble/decoder_model.pt\"))\n",
    "loaded_decoder_model.eval()\n",
    "\n",
    "\n",
    "# loaded_encoder_model = torch.load(\"SavedModels/Jumble/encoder_model.pt\")\n",
    "# loaded_decoder_model = torch.load(\"SavedModels/Jumble/decoder_model.pt\")\n",
    "# model_attention = torch.load(\"SavedModels/Jumble/attention_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jumbled_sent</th>\n",
       "      <th>unjumbled_sent</th>\n",
       "      <th>prediction</th>\n",
       "      <th>hard_accuracy</th>\n",
       "      <th>soft_accuracy</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is eating . Nitish apple &lt;eos&gt;</td>\n",
       "      <td>Nitish is eating apple . &lt;eos&gt;</td>\n",
       "      <td>girl sits &lt;unk&gt; by fish stand &lt;eos&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is city my favorite New York. &lt;eos&gt;</td>\n",
       "      <td>New York is my faorite city. &lt;eos&gt;</td>\n",
       "      <td>girl stand onstage stand near ocean &lt;eos&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a a and dog are man woods walking through the ...</td>\n",
       "      <td>a man and a dog are walking through the woods ...</td>\n",
       "      <td>large dog walks toward snow &lt;unk&gt; ball wears d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        jumbled_sent  \\\n",
       "0                     is eating . Nitish apple <eos>   \n",
       "1                is city my favorite New York. <eos>   \n",
       "2  a a and dog are man woods walking through the ...   \n",
       "\n",
       "                                      unjumbled_sent  \\\n",
       "0                     Nitish is eating apple . <eos>   \n",
       "1                 New York is my faorite city. <eos>   \n",
       "2  a man and a dog are walking through the woods ...   \n",
       "\n",
       "                                          prediction  hard_accuracy  \\\n",
       "0                girl sits <unk> by fish stand <eos>              0   \n",
       "1          girl stand onstage stand near ocean <eos>              0   \n",
       "2  large dog walks toward snow <unk> ball wears d...              0   \n",
       "\n",
       "   soft_accuracy  word_count  \n",
       "0       0.166667           6  \n",
       "1       0.142857           7  \n",
       "2       0.272727          11  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_tuple_list_test = predict_on_test(loaded_encoder_model,loaded_decoder_model,encoder_encode_decode,decoder_itow,decoder_wtoi)\n",
    "df_test = pd.DataFrame(accuracy_tuple_list_test)\n",
    "df_test.columns = [\"jumbled_sent\",\"unjumbled_sent\",\"prediction\",\"hard_accuracy\",\"soft_accuracy\",\"word_count\"]\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
