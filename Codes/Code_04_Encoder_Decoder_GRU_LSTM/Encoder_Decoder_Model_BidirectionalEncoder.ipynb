{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> In this notebook, we will try to unjumble a sentence using Encoder-Decoder Architecture built using <br><br>\n",
    " Recurrent Networks like GRU, LSTM and Bi-directional LSTMs.</h6>\n",
    "<h6> The Data is located here: ../../Datasets/Jumble_Unjumble/ </h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"../../Datasets/Jumble_Unjumble/Train_400.tsv\",sep=\"\\t\")\n",
    "# test_df = pd.read_csv(\"../../Datasets/Jumble_Unjumble/Test_100.tsv\",sep=\"\\t\")\n",
    "# print(train_df.shape, test_df.shape)\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32368, 2) (8092, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jumbled_sentences</th>\n",
       "      <th>unjumbled_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32760</th>\n",
       "      <td>tools and a man gardening inside two holding a...</td>\n",
       "      <td>a man and two women are inside a greenhouse ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31413</th>\n",
       "      <td>meandering at people of the walkway stand . up...</td>\n",
       "      <td>people stand at the bottom of a meandering wal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325</th>\n",
       "      <td>standing a rock . on man view the shorts a out...</td>\n",
       "      <td>a man in shorts is standing on a rock looking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28232</th>\n",
       "      <td>to a a in on shirt little red a holds pole nea...</td>\n",
       "      <td>a little girl in a red shirt holds on to a pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28438</th>\n",
       "      <td>children two in &lt;unk&gt; play the melting .</td>\n",
       "      <td>two children play in the melting &lt;unk&gt; .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       jumbled_sentences  \\\n",
       "32760  tools and a man gardening inside two holding a...   \n",
       "31413  meandering at people of the walkway stand . up...   \n",
       "4325   standing a rock . on man view the shorts a out...   \n",
       "28232  to a a in on shirt little red a holds pole nea...   \n",
       "28438          children two in <unk> play the melting .    \n",
       "\n",
       "                                     unjumbled_sentences  \n",
       "32760  a man and two women are inside a greenhouse ho...  \n",
       "31413  people stand at the bottom of a meandering wal...  \n",
       "4325   a man in shorts is standing on a rock looking ...  \n",
       "28232  a little girl in a red shirt holds on to a pol...  \n",
       "28438          two children play in the melting <unk> .   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jumbled_df = pd.read_csv(\"../../Datasets/Jumble_Unjumble/processed_jumbled.txt\",sep=\"\\t\",header=None)\n",
    "unjumbled_df = pd.read_csv(\"../../Datasets/Jumble_Unjumble/processed_unjumbled.txt\",sep=\"\\t\",header=None)\n",
    "jumbled_df.columns = [\"jumbled_sentences\"]\n",
    "unjumbled_df.columns = [\"unjumbled_sentences\"]\n",
    "df = pd.concat([jumbled_df,unjumbled_df],axis=1)\n",
    "train_df = df.sample(frac=0.8, random_state=42) \n",
    "test_df = df.drop(train_df.index)\n",
    "print(train_df.shape, test_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Vocab using jumbled_sentences of Train + Test dataset. Ideally only Train dataset should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabBuilder:\n",
    "    def __init__(self,text_corpus,unknown_token=None,pad_token=None,sos_token=None,eos_token=None):\n",
    "        '''\n",
    "        text_corpus = \"This is first sentence. This is second sentence. This is another sentence\"\n",
    "        '''\n",
    "        self.text_corpus = text_corpus\n",
    "        self.unknown_token = unknown_token or \"<unk>\"\n",
    "        self.pad_token = pad_token or \"<pad>\"\n",
    "        self.sos_token = sos_token or \"<sos>\"\n",
    "        self.eos_token = eos_token or \"<eos>\"\n",
    "        self.word_to_index, self.index_to_word = self.get_vocabs()\n",
    "                        \n",
    "    def get_vocabs(self):\n",
    "        word_to_index = {}\n",
    "        index_count = 0\n",
    "        all_unique_words = set(self.text_corpus.split(\" \"))\n",
    "        for index, word in enumerate(all_unique_words):\n",
    "            word_to_index[word] = index\n",
    "        if self.pad_token not in word_to_index: word_to_index[self.pad_token] = index + 1\n",
    "        if self.sos_token not in word_to_index: word_to_index[self.sos_token] = index + 2\n",
    "        if self.eos_token not in word_to_index: word_to_index[self.eos_token] = index + 3\n",
    "        if self.unknown_token not in word_to_index: word_to_index[self.unknown_token] = index + 4\n",
    "        index_to_word = {v:k for k,v in word_to_index.items()}\n",
    "        return word_to_index, index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tools and a man gardening inside two holding are . women a greenhouse  meandering at people of the walkway stand . uphill that bottom goes a  standing a rock . on man view the shorts a out from lookin\n"
     ]
    }
   ],
   "source": [
    "text_corpus_1 = \" \".join(train_df[\"jumbled_sentences\"].tolist())\n",
    "text_corpus_2 = \" \".join(test_df[\"jumbled_sentences\"].tolist())\n",
    "text_corpus = text_corpus_1 + \" \" + text_corpus_2\n",
    "print(text_corpus[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordToIndex Dict length: 5242\n",
      "IndexToWord Dict length: 5242\n"
     ]
    }
   ],
   "source": [
    "unknown_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "vocab_builder = VocabBuilder(text_corpus,unknown_token,pad_token,sos_token,eos_token)\n",
    "print(\"WordToIndex Dict length:\",len(vocab_builder.word_to_index))\n",
    "print(\"IndexToWord Dict length:\",len(vocab_builder.index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create X_Encoder, X_Decoder and Y\n",
    "X_encoder is the matrix of words in jumbled_sentences, each sentence suffixed by \"eos\" token <br>\n",
    "X_decoder is the matrix of unjumbled_sentences, each sentence prefixed by \"sos\" token <br>\n",
    "Y is the matrix of unjumbled_sentences, each sentence suffixed by \"eos\" token <br>\n",
    "\n",
    "Do this for both train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Encoder train length: 32368\n",
      "X Encoder test length: 8092\n",
      "Sample X_encoder_train: ['tools', 'and', 'a', 'man', 'gardening', 'inside', 'two', 'holding', 'are', '.', 'women', 'a', 'greenhouse', '', '<eos>']\n",
      "Sample X_decoder_train: ['<sos>', 'a', 'man', 'and', 'two', 'women', 'are', 'inside', 'a', 'greenhouse', 'holding', 'gardening', 'tools', '.', '']\n",
      "Sample Y_train: ['a', 'man', 'and', 'two', 'women', 'are', 'inside', 'a', 'greenhouse', 'holding', 'gardening', 'tools', '.', '', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "def get_Xe_Xd_Y(dataframe, sos_token, eos_token):\n",
    "    jumbled_sentences = dataframe[\"jumbled_sentences\"].tolist()\n",
    "    unjumbled_sentences = dataframe[\"unjumbled_sentences\"].tolist()\n",
    "    X_encoder_words = [el.split(\" \") + [eos_token] for el in jumbled_sentences]\n",
    "    X_decoder_words = [[sos_token] + el.split(\" \") for el in unjumbled_sentences]\n",
    "    Y_words = [el.split(\" \") + [eos_token] for el in unjumbled_sentences]\n",
    "    return X_encoder_words, X_decoder_words, Y_words\n",
    "\n",
    "X_encoder_words_tr, X_decoder_words_tr, Y_words_tr = get_Xe_Xd_Y(train_df, sos_token, eos_token)\n",
    "X_encoder_words_test, X_decoder_words_test, Y_words_test = get_Xe_Xd_Y(test_df, sos_token, eos_token)\n",
    "print(\"X Encoder train length:\",len(X_encoder_words_tr))\n",
    "print(\"X Encoder test length:\",len(X_encoder_words_test))\n",
    "print(\"Sample X_encoder_train:\",X_encoder_words_tr[0])\n",
    "print(\"Sample X_decoder_train:\",X_decoder_words_tr[0])\n",
    "print(\"Sample Y_train:\",Y_words_tr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map X_encoder, X_decoder and Y using Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word_Index_Mapper:\n",
    "    def __init__(self,word_to_index,index_to_word, unknown_token):\n",
    "        self.word_to_index = word_to_index\n",
    "        self.index_to_word = index_to_word\n",
    "        self.unknown_token = unknown_token\n",
    "    \n",
    "    def get_encoding(self,sentence):\n",
    "        '''\n",
    "        sentence must be a list of words.\n",
    "        Ex: [\"Climate\",\"change\",\"is\",\"a\",\"pressing\",\"global\",\"issue\"]\n",
    "        '''\n",
    "        encoded_sentence = []\n",
    "        for word in sentence:\n",
    "            if word in self.word_to_index: encoded_sentence.append(self.word_to_index[word])\n",
    "            else: encoded_sentence.append(self.word_to_index[self.unknown_token])\n",
    "        return encoded_sentence\n",
    "    \n",
    "    def get_decoding(self,encoded_sentence):\n",
    "        '''\n",
    "        encoded_sentence must be a list of vocab indices.\n",
    "        Ex: encoded_sentence = [24,21,4,1,..] \n",
    "        '''\n",
    "        sentence = [self.index_to_word[index] for index in encoded_sentence]\n",
    "        return \" \".join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_words_to_indices(word_index_mapper, max_sequence_length, word_matrix):\n",
    "    index_matrix = []\n",
    "    for el in word_matrix:\n",
    "        el = el[:max_sequence_length]\n",
    "        if len(el) < max_sequence_length:\n",
    "            pad_tokens_to_append = max_sequence_length - len(el)\n",
    "            el = el + [pad_token]*pad_tokens_to_append\n",
    "        index_matrix.append(word_index_mapper.get_encoding(el))\n",
    "    return index_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Encoder train length: 32368\n",
      "X Encoder test length: 8092\n",
      "Sample X_encoder_train: [857, 3489, 4223, 4354, 1988, 2041, 3618, 58, 5033, 3732, 412, 4223, 2350, 0, 5241, 5239, 5239, 5239, 5239, 5239, 5239, 5239, 5239, 5239, 5239]\n",
      "Sample X_decoder_train: [5240, 4223, 4354, 3489, 3618, 412, 5033, 2041, 4223, 2350, 58, 1988, 857, 3732, 0, 5239, 5239, 5239, 5239, 5239, 5239, 5239, 5239, 5239, 5239]\n",
      "Sample Y_train: [4223, 4354, 3489, 3618, 412, 5033, 2041, 4223, 2350, 58, 1988, 857, 3732, 0, 5241, 5239, 5239, 5239, 5239, 5239, 5239, 5239, 5239, 5239, 5239]\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 25\n",
    "word_index_mapper = Word_Index_Mapper(vocab_builder.word_to_index, vocab_builder.index_to_word, unknown_token)\n",
    "X_encoder_indices_tr = map_words_to_indices(word_index_mapper, max_sequence_length, X_encoder_words_tr)\n",
    "X_decoder_indices_tr = map_words_to_indices(word_index_mapper, max_sequence_length, X_decoder_words_tr)\n",
    "Y_indices_tr = map_words_to_indices(word_index_mapper, max_sequence_length, Y_words_tr)\n",
    "X_encoder_indices_test = map_words_to_indices(word_index_mapper, max_sequence_length, X_encoder_words_test)\n",
    "X_decoder_indices_test = map_words_to_indices(word_index_mapper, max_sequence_length, X_decoder_words_test)\n",
    "Y_indices_test = map_words_to_indices(word_index_mapper, max_sequence_length, Y_words_test)\n",
    "print(\"X Encoder train length:\",len(X_encoder_indices_tr))\n",
    "print(\"X Encoder test length:\",len(X_encoder_indices_test))\n",
    "print(\"Sample X_encoder_train:\",X_encoder_indices_tr[0])\n",
    "print(\"Sample X_decoder_train:\",X_decoder_indices_tr[0])\n",
    "print(\"Sample Y_train:\",Y_indices_tr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unknown token statistics - must be 0, as both Train and Test dataset has been used for vocab creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741\n",
      "<sos> a small child grips onto the red ropes at the playground .  <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "X_test_temp = []\n",
    "unknown_token_counts = 0\n",
    "for el in X_decoder_indices_test:\n",
    "    temp_list = word_index_mapper.get_decoding(el)\n",
    "    unknown_token_counts += temp_list.count(unknown_token)\n",
    "    X_test_temp.append(temp_list)\n",
    "print(unknown_token_counts)\n",
    "print(X_test_temp[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, dropout, debug):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.debug = debug\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True, bidirectional = True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        dropped_out = self.dropout(embedded) \n",
    "        output, hidden = self.gru(dropped_out)\n",
    "        hidden_concatenated = torch.cat((hidden[-1],hidden[-2]),axis=1)\n",
    "        hidden_unsqueezed = hidden_concatenated.unsqueeze(0)\n",
    "        if self.debug: \n",
    "            print(\"-----------Encoder----------:\")\n",
    "            print(\"Input Data shape:\",x.shape)\n",
    "            print(\"After Embedding Layer:\",embedded.shape)\n",
    "            print(\"After Dropout Layer:\",dropped_out.shape)\n",
    "            print(\"Outputs and hidden shape from GRU:\",output.shape, hidden.shape)\n",
    "            print(\"Concatenated hidden shape:\", hidden_concatenated.shape)\n",
    "            print(\"Unsqueezed hidden shape:\", hidden_unsqueezed.shape)\n",
    "        return output, hidden_unsqueezed\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, debug):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.debug = debug\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hid_dim,  batch_first=True)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, encoder_hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.gru(embedded, encoder_hidden)\n",
    "        reshaped_output = output.reshape(-1,output.shape[2])\n",
    "        prediction = self.fc_out(reshaped_output)\n",
    "        if self.debug: \n",
    "            print(\"-----------Decoder----------:\")\n",
    "            print(\"Input Data shape, X:\",x.shape, \", Encoder hidden state:\", encoder_hidden.shape)\n",
    "            print(\"After Embedding Layer:\",embedded.shape)\n",
    "            print(\"Outputs and hidden shape from GRU:\",output.shape, hidden.shape)\n",
    "            print(\"Reshaped Output:\", reshaped_output.shape)\n",
    "            print(\"After FC layer:\", prediction.shape)\n",
    "        return prediction, hidden\n",
    "    \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__() \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, encoder_input, decoder_input, teacher_forcing_ratio=0.5): \n",
    "        encoder_outputs, encoder_hidden = self.encoder(encoder_input) \n",
    "        outputs, _ = self.decoder(decoder_input,encoder_hidden)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X_encoder_indices_test, X_decoder_indices_test, \n",
    "            X_encoder_words_test, X_decoder_words_test,\n",
    "            word_index_mapper, device):\n",
    "    data_index = random.randint(0,100)\n",
    "    Xe_b = torch.tensor([X_encoder_indices_test[data_index]]).to(device)\n",
    "    print(data_index)\n",
    "    print(X_encoder_words_test[data_index])\n",
    "    print(X_decoder_words_test[data_index])\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        ht,ht_for_decoder = model.encoder(Xe_b)\n",
    "        sos_word = torch.tensor([[word_index_mapper.word_to_index[\"<sos>\"]]]).to(device)\n",
    "        op,ht = model.decoder(sos_word,ht_for_decoder)\n",
    "        unjumbled_sentence = []\n",
    "        for i in range(25):\n",
    "            predicted_word = torch.argmax(op,axis=1).tolist()\n",
    "#             print(\"Predicted .....................\",predicted_word)\n",
    "            if predicted_word[0] == word_index_mapper.word_to_index[\"<eos>\"]: break\n",
    "            unjumbled_sentence.append(word_index_mapper.index_to_word[predicted_word[0]])\n",
    "            op,ht = model.decoder(torch.tensor([predicted_word]).to(device),ht)\n",
    "        print(\"_______________________________________\")\n",
    "        print(unjumbled_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Training And Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(word_index_mapper.word_to_index) # Size of source vocabulary \n",
    "OUTPUT_DIM = len(word_index_mapper.word_to_index) # Size of target vocabulary \n",
    "ENC_EMB_DIM = 256 \n",
    "DEC_EMB_DIM = 256 \n",
    "HID_DIM = 512 \n",
    "N_LAYERS = 2 \n",
    "ENC_DROPOUT = 0.5 \n",
    "DEC_DROPOUT = 0.5\n",
    "device = \"cpu\"\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT, debug = True) \n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM*2, debug = True) \n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters()) \n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_index_mapper.word_to_index[\"<pad>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 25]) torch.Size([5, 25]) torch.Size([5, 25])\n",
      "-----------Encoder----------:\n",
      "Input Data shape: torch.Size([5, 25])\n",
      "After Embedding Layer: torch.Size([5, 25, 256])\n",
      "After Dropout Layer: torch.Size([5, 25, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([5, 25, 1024]) torch.Size([2, 5, 512])\n",
      "Concatenated hidden shape: torch.Size([5, 1024])\n",
      "Unsqueezed hidden shape: torch.Size([1, 5, 1024])\n",
      "-----------Decoder----------:\n",
      "Input Data shape, X: torch.Size([5, 25]) , Encoder hidden state: torch.Size([1, 5, 1024])\n",
      "After Embedding Layer: torch.Size([5, 25, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([5, 25, 1024]) torch.Size([1, 5, 1024])\n",
      "Reshaped Output: torch.Size([125, 1024])\n",
      "After FC layer: torch.Size([125, 5242])\n",
      "---------------------------------------------\n",
      "torch.Size([5, 25]) torch.Size([5, 25]) torch.Size([5, 25])\n",
      "-----------Encoder----------:\n",
      "Input Data shape: torch.Size([5, 25])\n",
      "After Embedding Layer: torch.Size([5, 25, 256])\n",
      "After Dropout Layer: torch.Size([5, 25, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([5, 25, 1024]) torch.Size([2, 5, 512])\n",
      "Concatenated hidden shape: torch.Size([5, 1024])\n",
      "Unsqueezed hidden shape: torch.Size([1, 5, 1024])\n",
      "-----------Decoder----------:\n",
      "Input Data shape, X: torch.Size([5, 25]) , Encoder hidden state: torch.Size([1, 5, 1024])\n",
      "After Embedding Layer: torch.Size([5, 25, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([5, 25, 1024]) torch.Size([1, 5, 1024])\n",
      "Reshaped Output: torch.Size([125, 1024])\n",
      "After FC layer: torch.Size([125, 5242])\n"
     ]
    }
   ],
   "source": [
    "data_index = 6\n",
    "batch_size = 5\n",
    "model.train()\n",
    "\n",
    "optimizer.zero_grad()\n",
    "Xe_b = torch.tensor(X_encoder_indices_tr[data_index:data_index+batch_size]).to(device)\n",
    "Xd_b = torch.tensor(X_decoder_indices_tr[data_index:data_index+batch_size]).to(device)\n",
    "Y_b = torch.tensor(Y_indices_tr[data_index:data_index+batch_size]).to(device)\n",
    "print(Xe_b.shape,Xd_b.shape,Y_b.shape)\n",
    "\n",
    "output = model(Xe_b, Xd_b)\n",
    "loss = criterion(output, Y_b.view(-1))\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(\"---------------------------------------------\")\n",
    "optimizer.zero_grad()\n",
    "Xe_b = torch.tensor(X_encoder_indices_tr[data_index+1:data_index+batch_size+1]).to(device)\n",
    "Xd_b = torch.tensor(X_decoder_indices_tr[data_index+1:data_index+batch_size+1]).to(device)\n",
    "Y_b = torch.tensor(Y_indices_tr[data_index+1:data_index+batch_size+1]).to(device)\n",
    "print(Xe_b.shape,Xd_b.shape,Y_b.shape)\n",
    "\n",
    "output = model(Xe_b, Xd_b)\n",
    "loss = criterion(output, Y_b.view(-1))\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "['a', 'jumping', 'a', 'water', 'boy', 'on', '<unk>', '', '<eos>']\n",
      "['<sos>', 'a', 'boy', 'jumping', 'on', 'a', 'water', '<unk>', '']\n",
      "-----------Encoder----------:\n",
      "Input Data shape: torch.Size([1, 25])\n",
      "After Embedding Layer: torch.Size([1, 25, 256])\n",
      "After Dropout Layer: torch.Size([1, 25, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([1, 25, 1024]) torch.Size([2, 1, 512])\n",
      "Concatenated hidden shape: torch.Size([1, 1024])\n",
      "Unsqueezed hidden shape: torch.Size([1, 1, 1024])\n",
      "-----------Decoder----------:\n",
      "Input Data shape, X: torch.Size([1, 1]) , Encoder hidden state: torch.Size([1, 1, 1024])\n",
      "After Embedding Layer: torch.Size([1, 1, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([1, 1, 1024]) torch.Size([1, 1, 1024])\n",
      "Reshaped Output: torch.Size([1, 1024])\n",
      "After FC layer: torch.Size([1, 5242])\n",
      "-----------Decoder----------:\n",
      "Input Data shape, X: torch.Size([1, 1]) , Encoder hidden state: torch.Size([1, 1, 1024])\n",
      "After Embedding Layer: torch.Size([1, 1, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([1, 1, 1024]) torch.Size([1, 1, 1024])\n",
      "Reshaped Output: torch.Size([1, 1024])\n",
      "After FC layer: torch.Size([1, 5242])\n",
      "-----------Decoder----------:\n",
      "Input Data shape, X: torch.Size([1, 1]) , Encoder hidden state: torch.Size([1, 1, 1024])\n",
      "After Embedding Layer: torch.Size([1, 1, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([1, 1, 1024]) torch.Size([1, 1, 1024])\n",
      "Reshaped Output: torch.Size([1, 1024])\n",
      "After FC layer: torch.Size([1, 5242])\n",
      "-----------Decoder----------:\n",
      "Input Data shape, X: torch.Size([1, 1]) , Encoder hidden state: torch.Size([1, 1, 1024])\n",
      "After Embedding Layer: torch.Size([1, 1, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([1, 1, 1024]) torch.Size([1, 1, 1024])\n",
      "Reshaped Output: torch.Size([1, 1024])\n",
      "After FC layer: torch.Size([1, 5242])\n",
      "-----------Decoder----------:\n",
      "Input Data shape, X: torch.Size([1, 1]) , Encoder hidden state: torch.Size([1, 1, 1024])\n",
      "After Embedding Layer: torch.Size([1, 1, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([1, 1, 1024]) torch.Size([1, 1, 1024])\n",
      "Reshaped Output: torch.Size([1, 1024])\n",
      "After FC layer: torch.Size([1, 5242])\n",
      "-----------Decoder----------:\n",
      "Input Data shape, X: torch.Size([1, 1]) , Encoder hidden state: torch.Size([1, 1, 1024])\n",
      "After Embedding Layer: torch.Size([1, 1, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([1, 1, 1024]) torch.Size([1, 1, 1024])\n",
      "Reshaped Output: torch.Size([1, 1024])\n",
      "After FC layer: torch.Size([1, 5242])\n",
      "-----------Decoder----------:\n",
      "Input Data shape, X: torch.Size([1, 1]) , Encoder hidden state: torch.Size([1, 1, 1024])\n",
      "After Embedding Layer: torch.Size([1, 1, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([1, 1, 1024]) torch.Size([1, 1, 1024])\n",
      "Reshaped Output: torch.Size([1, 1024])\n",
      "After FC layer: torch.Size([1, 5242])\n",
      "-----------Decoder----------:\n",
      "Input Data shape, X: torch.Size([1, 1]) , Encoder hidden state: torch.Size([1, 1, 1024])\n",
      "After Embedding Layer: torch.Size([1, 1, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([1, 1, 1024]) torch.Size([1, 1, 1024])\n",
      "Reshaped Output: torch.Size([1, 1024])\n",
      "After FC layer: torch.Size([1, 5242])\n",
      "-----------Decoder----------:\n",
      "Input Data shape, X: torch.Size([1, 1]) , Encoder hidden state: torch.Size([1, 1, 1024])\n",
      "After Embedding Layer: torch.Size([1, 1, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([1, 1, 1024]) torch.Size([1, 1, 1024])\n",
      "Reshaped Output: torch.Size([1, 1024])\n",
      "After FC layer: torch.Size([1, 5242])\n",
      "-----------Decoder----------:\n",
      "Input Data shape, X: torch.Size([1, 1]) , Encoder hidden state: torch.Size([1, 1, 1024])\n",
      "After Embedding Layer: torch.Size([1, 1, 256])\n",
      "Outputs and hidden shape from GRU: torch.Size([1, 1, 1024]) torch.Size([1, 1, 1024])\n",
      "Reshaped Output: torch.Size([1, 1024])\n",
      "After FC layer: torch.Size([1, 5242])\n",
      "_______________________________________\n",
      "['a', 'a', 'a', 'a', 'a', 'the', 'the', '.', '']\n"
     ]
    }
   ],
   "source": [
    "predict(model,X_encoder_indices_test,X_decoder_indices_test, X_encoder_words_test, X_decoder_words_test, word_index_mapper, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" #torch.device(\"cuda:0\")\n",
    "batch_size = 50\n",
    "INPUT_DIM = len(word_index_mapper.word_to_index) # Size of source vocabulary \n",
    "OUTPUT_DIM = len(word_index_mapper.word_to_index) # Size of target vocabulary \n",
    "ENC_EMB_DIM = 128 \n",
    "DEC_EMB_DIM = 128 \n",
    "HID_DIM = 250 \n",
    "N_LAYERS = 2 \n",
    "ENC_DROPOUT = 0.5 \n",
    "DEC_DROPOUT = 0.5\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT, debug = False) \n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM*2, debug = False) \n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters()) \n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_index_mapper.word_to_index[\"<pad>\"])\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 0 Loss: 0.06488276273012161\n",
      "Epoch: 0 Batch: 1000 Loss: 0.08332639932632446\n",
      "Epoch: 0 Batch: 2000 Loss: 0.09826172143220901\n",
      "Epoch: 0 Batch: 3000 Loss: 0.0484938807785511\n",
      "Epoch: 0 Batch: 4000 Loss: 0.0832718014717102\n",
      "Epoch: 0 Batch: 5000 Loss: 0.05295179411768913\n",
      "Epoch: 0 Batch: 6000 Loss: 0.09563960134983063\n",
      "Epoch: 0 Batch: 7000 Loss: 0.05169978365302086\n",
      "Epoch: 0 Batch: 8000 Loss: 0.07165710628032684\n",
      "Epoch: 0 Batch: 9000 Loss: 0.07759127020835876\n",
      "Epoch: 0 Batch: 10000 Loss: 0.07503162324428558\n",
      "Epoch: 0 Batch: 11000 Loss: 0.044686101377010345\n",
      "Epoch: 0 Batch: 12000 Loss: 0.08322243392467499\n",
      "Epoch: 0 Batch: 13000 Loss: 0.07350403070449829\n",
      "Epoch: 0 Batch: 14000 Loss: 0.06829915940761566\n",
      "Epoch: 0 Batch: 15000 Loss: 0.06235787272453308\n",
      "Epoch: 0 Batch: 16000 Loss: 0.06498934328556061\n",
      "Epoch: 0 Batch: 17000 Loss: 0.055059801787137985\n",
      "Epoch: 0 Batch: 18000 Loss: 0.08079463243484497\n",
      "Epoch: 0 Batch: 19000 Loss: 0.08060895651578903\n",
      "Epoch: 0 Batch: 20000 Loss: 0.06775505840778351\n",
      "Epoch: 0 Batch: 21000 Loss: 0.08032862842082977\n",
      "Epoch: 0 Batch: 22000 Loss: 0.07423245161771774\n",
      "Epoch: 0 Batch: 23000 Loss: 0.07397469133138657\n",
      "Epoch: 0 Batch: 24000 Loss: 0.06451529264450073\n",
      "Epoch: 0 Batch: 25000 Loss: 0.07943093776702881\n",
      "Epoch: 0 Batch: 26000 Loss: 0.06619053333997726\n",
      "Epoch: 0 Batch: 27000 Loss: 0.05454171448945999\n",
      "Epoch: 0 Batch: 28000 Loss: 0.08422239124774933\n",
      "Epoch: 0 Batch: 29000 Loss: 0.06693325191736221\n",
      "Epoch: 0 Batch: 30000 Loss: 0.09103900194168091\n",
      "Epoch: 0 Batch: 31000 Loss: 0.04659692943096161\n",
      "Epoch: 0 Batch: 32000 Loss: 0.07203632593154907\n",
      "______________________________________\n",
      "Epoch Loss: 46.525323536247015\n",
      "63\n",
      "['and', 'catch', 'in', 'for', '.', 'a', 'waiting', 'come', 'him', 'throwing', 'air', 'up', 'the', 'water', 'so', 'him', 'man', 'can', 'in', 'a', 'down', 'boy', 'he', 'little', 'to', '', '<eos>']\n",
      "['<sos>', 'a', 'man', 'in', 'water', 'throwing', 'a', 'little', 'boy', 'up', 'in', 'the', 'air', 'and', 'waiting', 'for', 'him', 'to', 'come', 'down', 'so', 'he', 'can', 'catch', 'him', '.', '']\n",
      "_______________________________________\n",
      "['a', 'man', 'in', 'water', 'safety', 'jacket', 'and', 'a', 'little', 'boy', 'watch', 'him', 'and', 'waiting', 'to', 'play', 'ball', 'with', 'her', 'arm', 'up', 'in', 'the', 'air', '.']\n",
      "_______________________________________\n",
      "Epoch: 1 Batch: 0 Loss: 0.06745254248380661\n",
      "Epoch: 1 Batch: 1000 Loss: 0.07817066460847855\n",
      "Epoch: 1 Batch: 2000 Loss: 0.06450581550598145\n",
      "Epoch: 1 Batch: 3000 Loss: 0.07042739540338516\n",
      "Epoch: 1 Batch: 4000 Loss: 0.07873328775167465\n",
      "Epoch: 1 Batch: 5000 Loss: 0.0627569630742073\n",
      "Epoch: 1 Batch: 6000 Loss: 0.09883909672498703\n",
      "Epoch: 1 Batch: 7000 Loss: 0.08577091246843338\n",
      "Epoch: 1 Batch: 8000 Loss: 0.069610595703125\n",
      "Epoch: 1 Batch: 9000 Loss: 0.06911555677652359\n",
      "Epoch: 1 Batch: 10000 Loss: 0.06904822587966919\n",
      "Epoch: 1 Batch: 11000 Loss: 0.07624195516109467\n",
      "Epoch: 1 Batch: 12000 Loss: 0.1132192462682724\n",
      "Epoch: 1 Batch: 13000 Loss: 0.060727205127477646\n",
      "Epoch: 1 Batch: 14000 Loss: 0.053977418690919876\n",
      "Epoch: 1 Batch: 15000 Loss: 0.06139487028121948\n",
      "Epoch: 1 Batch: 16000 Loss: 0.04975847899913788\n",
      "Epoch: 1 Batch: 17000 Loss: 0.05869830399751663\n",
      "Epoch: 1 Batch: 18000 Loss: 0.06470468640327454\n",
      "Epoch: 1 Batch: 19000 Loss: 0.07987435162067413\n",
      "Epoch: 1 Batch: 20000 Loss: 0.046527937054634094\n",
      "Epoch: 1 Batch: 21000 Loss: 0.07649261504411697\n",
      "Epoch: 1 Batch: 22000 Loss: 0.06531482934951782\n",
      "Epoch: 1 Batch: 23000 Loss: 0.05333568528294563\n",
      "Epoch: 1 Batch: 24000 Loss: 0.08359207957983017\n",
      "Epoch: 1 Batch: 25000 Loss: 0.06399857997894287\n",
      "Epoch: 1 Batch: 26000 Loss: 0.08946637809276581\n",
      "Epoch: 1 Batch: 27000 Loss: 0.07409903407096863\n",
      "Epoch: 1 Batch: 28000 Loss: 0.08614512532949448\n",
      "Epoch: 1 Batch: 29000 Loss: 0.084213025867939\n",
      "Epoch: 1 Batch: 30000 Loss: 0.06802798062562943\n",
      "Epoch: 1 Batch: 31000 Loss: 0.048116762191057205\n",
      "Epoch: 1 Batch: 32000 Loss: 0.04537409543991089\n",
      "______________________________________\n",
      "Epoch Loss: 44.84175609610975\n",
      "17\n",
      "['and', 'ice', '<unk>', 'picks', 'ice', 'man', 'uses', '.', 'a', 'to', '<unk>', '', '<eos>']\n",
      "['<sos>', 'a', 'man', 'uses', 'ice', 'picks', 'and', '<unk>', 'to', '<unk>', 'ice', '.', '']\n",
      "_______________________________________\n",
      "['a', 'man', '<unk>', 'to', '<unk>', 'juice', 'and', 'ice', 'cream', 'stand', '.', '']\n",
      "_______________________________________\n",
      "Epoch: 2 Batch: 0 Loss: 0.08138882368803024\n",
      "Epoch: 2 Batch: 1000 Loss: 0.09127982705831528\n",
      "Epoch: 2 Batch: 2000 Loss: 0.07920297980308533\n",
      "Epoch: 2 Batch: 3000 Loss: 0.06376134604215622\n",
      "Epoch: 2 Batch: 4000 Loss: 0.06380800157785416\n",
      "Epoch: 2 Batch: 5000 Loss: 0.07157429307699203\n",
      "Epoch: 2 Batch: 6000 Loss: 0.07153088599443436\n",
      "Epoch: 2 Batch: 7000 Loss: 0.09076470136642456\n",
      "Epoch: 2 Batch: 8000 Loss: 0.058308083564043045\n",
      "Epoch: 2 Batch: 9000 Loss: 0.05680057033896446\n",
      "Epoch: 2 Batch: 10000 Loss: 0.08850569278001785\n",
      "Epoch: 2 Batch: 11000 Loss: 0.07147650420665741\n",
      "Epoch: 2 Batch: 12000 Loss: 0.07254820317029953\n",
      "Epoch: 2 Batch: 13000 Loss: 0.03804397955536842\n",
      "Epoch: 2 Batch: 14000 Loss: 0.07200735807418823\n",
      "Epoch: 2 Batch: 15000 Loss: 0.0630820095539093\n",
      "Epoch: 2 Batch: 16000 Loss: 0.09135393053293228\n",
      "Epoch: 2 Batch: 17000 Loss: 0.042934346944093704\n",
      "Epoch: 2 Batch: 18000 Loss: 0.07037792354822159\n",
      "Epoch: 2 Batch: 19000 Loss: 0.06305886059999466\n",
      "Epoch: 2 Batch: 20000 Loss: 0.054076969623565674\n",
      "Epoch: 2 Batch: 21000 Loss: 0.073008231818676\n",
      "Epoch: 2 Batch: 22000 Loss: 0.05716704949736595\n",
      "Epoch: 2 Batch: 23000 Loss: 0.08496113866567612\n",
      "Epoch: 2 Batch: 24000 Loss: 0.08004142343997955\n",
      "Epoch: 2 Batch: 25000 Loss: 0.06959524005651474\n",
      "Epoch: 2 Batch: 26000 Loss: 0.05954642593860626\n",
      "Epoch: 2 Batch: 27000 Loss: 0.0973564013838768\n",
      "Epoch: 2 Batch: 28000 Loss: 0.05833863839507103\n",
      "Epoch: 2 Batch: 29000 Loss: 0.049691036343574524\n",
      "Epoch: 2 Batch: 30000 Loss: 0.06575711071491241\n",
      "Epoch: 2 Batch: 31000 Loss: 0.05263667553663254\n",
      "Epoch: 2 Batch: 32000 Loss: 0.06364152580499649\n",
      "______________________________________\n",
      "Epoch Loss: 45.47325884923339\n",
      "88\n",
      "['two', 'people', 'three', 'snowmobiles', 'and', '.', '', '<eos>']\n",
      "['<sos>', 'three', 'people', 'and', 'two', 'snowmobiles', '.', '']\n",
      "_______________________________________\n",
      "['two', 'people', 'and', 'two', 'people', '.', '']\n",
      "_______________________________________\n",
      "Epoch: 3 Batch: 0 Loss: 0.08644815534353256\n",
      "Epoch: 3 Batch: 1000 Loss: 0.06968989968299866\n",
      "Epoch: 3 Batch: 2000 Loss: 0.08851341158151627\n",
      "Epoch: 3 Batch: 3000 Loss: 0.045040011405944824\n",
      "Epoch: 3 Batch: 4000 Loss: 0.06104114651679993\n",
      "Epoch: 3 Batch: 5000 Loss: 0.06716912239789963\n",
      "Epoch: 3 Batch: 6000 Loss: 0.07924730330705643\n",
      "Epoch: 3 Batch: 7000 Loss: 0.06131244823336601\n",
      "Epoch: 3 Batch: 8000 Loss: 0.047066234052181244\n",
      "Epoch: 3 Batch: 9000 Loss: 0.06749722361564636\n",
      "Epoch: 3 Batch: 10000 Loss: 0.08266131579875946\n",
      "Epoch: 3 Batch: 11000 Loss: 0.06222215294837952\n",
      "Epoch: 3 Batch: 12000 Loss: 0.0958961471915245\n",
      "Epoch: 3 Batch: 13000 Loss: 0.07627321779727936\n",
      "Epoch: 3 Batch: 14000 Loss: 0.058901604264974594\n",
      "Epoch: 3 Batch: 15000 Loss: 0.062331318855285645\n",
      "Epoch: 3 Batch: 16000 Loss: 0.06602232903242111\n",
      "Epoch: 3 Batch: 17000 Loss: 0.06761222332715988\n",
      "Epoch: 3 Batch: 18000 Loss: 0.06829755008220673\n",
      "Epoch: 3 Batch: 19000 Loss: 0.050702840089797974\n",
      "Epoch: 3 Batch: 20000 Loss: 0.06556615233421326\n",
      "Epoch: 3 Batch: 21000 Loss: 0.07386106252670288\n",
      "Epoch: 3 Batch: 22000 Loss: 0.07606593519449234\n",
      "Epoch: 3 Batch: 23000 Loss: 0.07196822762489319\n",
      "Epoch: 3 Batch: 24000 Loss: 0.10056065022945404\n",
      "Epoch: 3 Batch: 25000 Loss: 0.05750425532460213\n",
      "Epoch: 3 Batch: 26000 Loss: 0.07033243775367737\n",
      "Epoch: 3 Batch: 27000 Loss: 0.0823245644569397\n",
      "Epoch: 3 Batch: 28000 Loss: 0.08706437796354294\n",
      "Epoch: 3 Batch: 29000 Loss: 0.07255107909440994\n",
      "Epoch: 3 Batch: 30000 Loss: 0.05827190354466438\n",
      "Epoch: 3 Batch: 31000 Loss: 0.05767357349395752\n",
      "Epoch: 3 Batch: 32000 Loss: 0.0617748387157917\n",
      "______________________________________\n",
      "Epoch Loss: 44.99156394228339\n",
      "80\n",
      "['on', 'of', 'ground', 'a', '.', 'group', 'backpackers', 'the', 'lay', 'dry', '', '<eos>']\n",
      "['<sos>', 'a', 'group', 'of', 'backpackers', 'lay', 'on', 'the', 'dry', 'ground', '.', '']\n",
      "_______________________________________\n",
      "['a', 'group', 'of', 'about', '11', 'walk', 'on', 'the', 'ground', '.', '']\n",
      "_______________________________________\n",
      "Epoch: 4 Batch: 0 Loss: 0.07829239964485168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Batch: 1000 Loss: 0.08501055091619492\n",
      "Epoch: 4 Batch: 2000 Loss: 0.05777866393327713\n",
      "Epoch: 4 Batch: 3000 Loss: 0.0744839534163475\n",
      "Epoch: 4 Batch: 4000 Loss: 0.07781413942575455\n",
      "Epoch: 4 Batch: 5000 Loss: 0.07074024528265\n",
      "Epoch: 4 Batch: 6000 Loss: 0.07213260233402252\n",
      "Epoch: 4 Batch: 7000 Loss: 0.0653424859046936\n",
      "Epoch: 4 Batch: 8000 Loss: 0.04089247062802315\n",
      "Epoch: 4 Batch: 9000 Loss: 0.07852138578891754\n",
      "Epoch: 4 Batch: 10000 Loss: 0.10024943202733994\n",
      "Epoch: 4 Batch: 11000 Loss: 0.056304190307855606\n",
      "Epoch: 4 Batch: 12000 Loss: 0.0796826034784317\n",
      "Epoch: 4 Batch: 13000 Loss: 0.04819009453058243\n",
      "Epoch: 4 Batch: 14000 Loss: 0.07925969362258911\n",
      "Epoch: 4 Batch: 15000 Loss: 0.060639213770627975\n",
      "Epoch: 4 Batch: 16000 Loss: 0.05457226559519768\n",
      "Epoch: 4 Batch: 17000 Loss: 0.05291018262505531\n",
      "Epoch: 4 Batch: 18000 Loss: 0.06610732525587082\n",
      "Epoch: 4 Batch: 19000 Loss: 0.07297436147928238\n",
      "Epoch: 4 Batch: 20000 Loss: 0.06230543926358223\n",
      "Epoch: 4 Batch: 21000 Loss: 0.06230843439698219\n",
      "Epoch: 4 Batch: 22000 Loss: 0.06093963235616684\n",
      "Epoch: 4 Batch: 23000 Loss: 0.10410112887620926\n",
      "Epoch: 4 Batch: 24000 Loss: 0.08947259187698364\n",
      "Epoch: 4 Batch: 25000 Loss: 0.06696126610040665\n",
      "Epoch: 4 Batch: 26000 Loss: 0.08825158327817917\n",
      "Epoch: 4 Batch: 27000 Loss: 0.07056646049022675\n",
      "Epoch: 4 Batch: 28000 Loss: 0.06276997923851013\n",
      "Epoch: 4 Batch: 29000 Loss: 0.06950681656599045\n",
      "Epoch: 4 Batch: 30000 Loss: 0.06256026774644852\n",
      "Epoch: 4 Batch: 31000 Loss: 0.06753867119550705\n",
      "Epoch: 4 Batch: 32000 Loss: 0.06816346198320389\n",
      "______________________________________\n",
      "Epoch Loss: 44.69572673924267\n",
      "14\n",
      "['.', 'a', 'at', 'watching', 'a', 'boy', 'lake', 'little', 'duck', 'a', '', '<eos>']\n",
      "['<sos>', 'a', 'little', 'boy', 'at', 'a', 'lake', 'watching', 'a', 'duck', '.', '']\n",
      "_______________________________________\n",
      "['a', 'little', 'boy', 'slide', 'at', 'a', 'little', 'girl', '.', '']\n",
      "_______________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "#     init_ht_for_encoder = model_encoder.init_hidden().to(device)\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for j in range(0,len(X_encoder_indices_tr),batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        Xe_b = torch.tensor(X_encoder_indices_tr[j:j+batch_size]).to(device)\n",
    "        Xd_b = torch.tensor(X_decoder_indices_tr[j:j+batch_size]).to(device)\n",
    "        Y_b = torch.tensor(Y_indices_tr[j:j+batch_size]).to(device)\n",
    "        op = model(Xe_b,Xd_b)\n",
    "        loss = criterion(op,Y_b.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss = loss.item()\n",
    "        epoch_loss += batch_loss\n",
    "        if j%1000 == 0: print(\"Epoch:\",i,\"Batch:\",j,\"Loss:\",batch_loss)\n",
    "    print(\"______________________________________\")\n",
    "    print(\"Epoch Loss:\",epoch_loss)\n",
    "    predict(model,X_encoder_indices_test,X_decoder_indices_test, \n",
    "            X_encoder_words_test, X_decoder_words_test, word_index_mapper, device)\n",
    "    print(\"_______________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 20])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5,10,20)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a[-2]\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 20])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.unsqueeze(dim=0)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 20])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = a.reshape(-1,a.shape[2])\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5242])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = torch.ones(8,5242)\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8]), tensor([0, 0, 0, 0, 0, 0, 0, 0]), [0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.argmax(e,axis=1)\n",
    "f.shape, f, f.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5242])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.softmax(e,axis=1)\n",
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
