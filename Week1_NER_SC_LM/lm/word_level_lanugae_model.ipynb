{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextReader:\n",
    "    def __init__(self,filename,code_file=False,lower_case=False):\n",
    "        self.filename = filename\n",
    "        self.code_file = code_file\n",
    "        self.lower_case = lower_case\n",
    "        \n",
    "    def get_all_words(self,regex_params=None):\n",
    "        '''\n",
    "        regex_params = {\n",
    "            \"uppercase\": True,\n",
    "            \"digits\":False,\n",
    "            \"punctuation_list\":None\n",
    "        }\n",
    "        '''\n",
    "        if regex_params:\n",
    "            regex_string = \"a-z\"\n",
    "            if regex_params[\"uppercase\"]: regex_string += \"A-Z\"\n",
    "            if regex_params[\"digits\"]: regex_string += \"0-9\"\n",
    "            if regex_params[\"punctuation_list\"]: regex_string += \"\".join(regex_params[\"punctuation_list\"])\n",
    "            regex_string = \"[\" + regex_string +\"]\"\n",
    "            with open(self.filename,\"r\") as f: text = f.read()\n",
    "            words = re.findall(regex_string,text)\n",
    "            return words\n",
    "        else:\n",
    "            with open(self.filename,\"r\") as f: words = f.read().split(\" \")\n",
    "            return words + [\" \"]\n",
    "        \n",
    "    def get_unique_words(self,regex_params=None, distinguish_casing=False):\n",
    "        '''\n",
    "        regex_params = {\n",
    "            \"uppercase\": True,\n",
    "            \"digits\":False,\n",
    "            \"punctuation_list\":None\n",
    "        }\n",
    "        '''\n",
    "        all_words = self.get_all_words(regex_params)\n",
    "        if not distinguish_casing: return list(set([word.lower() for word in all_words]))\n",
    "        else: return list(set(all_words))\n",
    "    \n",
    "    \n",
    "    def get_X_and_Y(self,window_size=10):\n",
    "        if self.code_file:\n",
    "            X,Y = [],[]\n",
    "            with open(self.filename,\"r\",errors=\"ignore\") as f:\n",
    "                for line in f:\n",
    "                    words = line.strip().split() + [\"\\n\"]\n",
    "                    if len(words) <= 2: continue\n",
    "                    x_w, y_w = [],[]\n",
    "                    if len(words) > window_size:\n",
    "                        for i in range(0,len(words)-window_size):\n",
    "                            x_w.append(words[i:i+window_size])\n",
    "                            y_w.append(words[i+1:i+1+window_size])\n",
    "                    else:\n",
    "                        x_w.append(words[:-1])\n",
    "                        y_w.append(words[1:])\n",
    "                    X += x_w\n",
    "                    Y += y_w\n",
    "                return X,Y\n",
    "        else:\n",
    "            with open(self.filename,\"r\",errors=\"ignore\") as f:\n",
    "                if self.lower_case: text = f.read().lower().split()\n",
    "                else: text = f.read().split()\n",
    "                X,Y = [],[]\n",
    "                for i in range(len(text)-window_size):\n",
    "                    X.append(text[i:i+window_size])\n",
    "                    Y.append(text[i+1:window_size+i+1])\n",
    "                return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168 2168 [['at', 'reading', 'rockets,', 'we', 'believe'], ['reading', 'rockets,', 'we', 'believe', 'in'], ['rockets,', 'we', 'believe', 'in', 'the'], ['we', 'believe', 'in', 'the', 'power']] [['reading', 'rockets,', 'we', 'believe', 'in'], ['rockets,', 'we', 'believe', 'in', 'the'], ['we', 'believe', 'in', 'the', 'power'], ['believe', 'in', 'the', 'power', 'of']] [['how', 'much', 'of', 'the', '1958'], ['much', 'of', 'the', '1958', 'paper'], ['of', 'the', '1958', 'paper', 'remains'], ['the', '1958', 'paper', 'remains', 'relevant']] [['much', 'of', 'the', '1958', 'paper'], ['of', 'the', '1958', 'paper', 'remains'], ['the', '1958', 'paper', 'remains', 'relevant'], ['1958', 'paper', 'remains', 'relevant', 'today.']]\n"
     ]
    }
   ],
   "source": [
    "text_reader = TextReader(\"data2.txt\",code_file=False,lower_case=True)\n",
    "X,Y = text_reader.get_X_and_Y(window_size=5)\n",
    "print(len(X),len(Y),X[:4],Y[:4],X[-4:],Y[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabBuilder:\n",
    "    def __init__(self, X,Y, unknown_token=\"<UNK>\",pad_token=\"<PAD>\"):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.unknown_token = unknown_token\n",
    "        self.pad_token = pad_token\n",
    "    \n",
    "    def get_word_vocab(self,for_X=False, for_Y=False, for_both=False):\n",
    "        word_to_index, index_to_word = {},{}\n",
    "        if for_X: all_words = list(set([word for el in self.X for word in el]))\n",
    "        if for_Y: all_words = list(set([word for el in self.Y for word in el]))\n",
    "        if for_both: all_words = list(set([word for el in self.Y for word in el] + [word for el in self.X for word in el]))\n",
    "        for i,word in enumerate(all_words):\n",
    "            word_to_index[word] = i\n",
    "            index_to_word[i] = word\n",
    "        len_vocab = len(word_to_index)\n",
    "        word_to_index[self.unknown_token] = len_vocab\n",
    "        index_to_word[len_vocab] = self.unknown_token\n",
    "        word_to_index[self.pad_token] = len_vocab+1\n",
    "        index_to_word[len_vocab+1] = self.pad_token\n",
    "        return word_to_index, index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(952, 953, 953)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_builder = VocabBuilder(X,Y)\n",
    "X_w, X_i = vocab_builder.get_word_vocab(for_X=True)\n",
    "Y_w, Y_i = vocab_builder.get_word_vocab(for_Y=True)\n",
    "A_w, A_i = vocab_builder.get_word_vocab(for_both=True)\n",
    "len(X_w),len(Y_w),len(A_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateEncoding:\n",
    "    def __init__(self,data_x,vocab_x,data_y,vocab_y,unknown_token):\n",
    "        self.data_x = data_x\n",
    "        self.vocab_x = vocab_x\n",
    "        self.data_y = data_y\n",
    "        self.vocab_y = vocab_y\n",
    "        self.unknown_token = unknown_token\n",
    "        self.pure_vocab_x = self.remove_unknown_token_from_voab(vocab_x)\n",
    "        self.pure_vocab_y = self.remove_unknown_token_from_voab(vocab_y)\n",
    "    \n",
    "    def remove_unknown_token_from_voab(self,vocab):\n",
    "        return {k:v for k,v in vocab.items() if k != self.unknown_token}\n",
    "        \n",
    "    def get_encoding_X(self,raw_text=None):\n",
    "        if raw_text: data_to_encode = raw_text\n",
    "        else: data_to_encode = self.data_x\n",
    "        encoded_X = []\n",
    "        for word_list in data_to_encode:\n",
    "            word_encoding = []\n",
    "            for word in word_list: \n",
    "                if word not in self.pure_vocab_x: word_encoding.append(self.vocab_x[self.unknown_token])\n",
    "                else: word_encoding.append(self.vocab_x[word])\n",
    "            encoded_X.append(word_encoding)\n",
    "        return encoded_X\n",
    "    \n",
    "    def get_encoding_Y(self,raw_text=None):\n",
    "        if raw_text: data_to_encode = raw_text\n",
    "        else: data_to_encode = self.data_y\n",
    "        encoded_Y = []\n",
    "        for word_list in data_to_encode:\n",
    "            word_encoding = []\n",
    "            for word in word_list: \n",
    "                if word not in self.pure_vocab_y: word_encoding.append(self.vocab_y[self.unknown_token])\n",
    "                else: word_encoding.append(self.vocab_y[word])\n",
    "            encoded_Y.append(word_encoding)\n",
    "        return encoded_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168 2168 [[660, 9, 72, 11, 304], [9, 72, 11, 304, 301], [72, 11, 304, 301, 3], [11, 304, 301, 3, 636]] [[9, 72, 11, 304, 301], [72, 11, 304, 301, 3], [11, 304, 301, 3, 636], [304, 301, 3, 636, 939]] [[5, 447, 939, 3, 326], [447, 939, 3, 326, 408], [939, 3, 326, 408, 946], [3, 326, 408, 946, 15]] [[447, 939, 3, 326, 408], [939, 3, 326, 408, 946], [3, 326, 408, 946, 15], [326, 408, 946, 15, 858]]\n"
     ]
    }
   ],
   "source": [
    "encoding_generator = GenerateEncoding(data_x=X,data_y=Y,vocab_x=A_w,vocab_y=A_w, unknown_token=\"<UNK>\")\n",
    "X_enc = encoding_generator.get_encoding_X()\n",
    "Y_enc = encoding_generator.get_encoding_Y()\n",
    "print(len(X_enc),len(Y_enc),X_enc[:4],Y_enc[:4],X_enc[-4:],Y_enc[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self,X,Y,batch_size):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def get_batch(self,batch_index,make_tensor=False):\n",
    "        Xb = self.X[batch_index*self.batch_size:(batch_index+1)*self.batch_size]\n",
    "        Yb = self.Y[batch_index*self.batch_size:(batch_index+1)*self.batch_size]\n",
    "        if make_tensor: return torch.tensor(Xb),torch.tensor(Yb)\n",
    "        return Xb,Yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyWordLevelRNNModel(nn.Module):\n",
    "    def __init__(self,vocab_size, embedding_dim, lstm_neurons, num_lstm_layers, num_classes,\n",
    "                 make_birectional=False, debug_mode=False):\n",
    "        super().__init__()\n",
    "        self.debug_mode = debug_mode\n",
    "        self.bidirectional = make_birectional\n",
    "        self.lstm_neurons = lstm_neurons\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=lstm_neurons, \n",
    "                            num_layers=num_lstm_layers, bidirectional=make_birectional, batch_first=True)\n",
    "        \n",
    "        in_features = lstm_neurons\n",
    "        if self.bidirectional: in_features = 2*lstm_neurons\n",
    "        self.linear1 = nn.Linear(in_features=in_features, out_features=100)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(in_features=100, out_features=num_classes)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self,x,ht,ct):\n",
    "        if self.debug_mode: print(\"Before embedding layer:\",x.shape)\n",
    "        x = self.embedding(x)\n",
    "        if self.debug_mode: print(\"After embedding layer:\",x.shape)\n",
    "        x, (ht, ct) = self.lstm(x,(ht,ct))\n",
    "        if self.debug_mode: print(\"After lstm layer:\",x.shape,ht.shape,ct.shape)\n",
    "        x = x.reshape(-1, x.shape[2])\n",
    "        if self.debug_mode: print(\"After reshaping:\",x.shape)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        if self.debug_mode: print(\"After 1st linear layer:\",x.shape)\n",
    "        x = self.linear2(x)\n",
    "        x = self.log_softmax(x)\n",
    "        if self.debug_mode: print(\"After 2nd linear layer:\",x.shape)\n",
    "        return x, ht,ct\n",
    "    \n",
    "    def init_state_of_lstm(self,batch_size):\n",
    "        if self.bidirectional: first_param = 2*self.num_lstm_layers\n",
    "        else: first_param = self.num_lstm_layers\n",
    "        return (\n",
    "            torch.randn(first_param, batch_size, self.lstm_neurons),\n",
    "            torch.randn(first_param, batch_size, self.lstm_neurons),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953 953\n",
      "2163 2163 [[660, 9, 72, 11, 304, 301, 3, 636, 939, 591], [9, 72, 11, 304, 301, 3, 636, 939, 591, 316], [72, 11, 304, 301, 3, 636, 939, 591, 316, 423], [11, 304, 301, 3, 636, 939, 591, 316, 423, 606]] [[9, 72, 11, 304, 301, 3, 636, 939, 591, 316], [72, 11, 304, 301, 3, 636, 939, 591, 316, 423], [11, 304, 301, 3, 636, 939, 591, 316, 423, 606], [304, 301, 3, 636, 939, 591, 316, 423, 606, 289]] [[546, 385, 194, 429, 788, 5, 447, 939, 3, 326], [385, 194, 429, 788, 5, 447, 939, 3, 326, 408], [194, 429, 788, 5, 447, 939, 3, 326, 408, 946], [429, 788, 5, 447, 939, 3, 326, 408, 946, 15]] [[385, 194, 429, 788, 5, 447, 939, 3, 326, 408], [194, 429, 788, 5, 447, 939, 3, 326, 408, 946], [429, 788, 5, 447, 939, 3, 326, 408, 946, 15], [788, 5, 447, 939, 3, 326, 408, 946, 15, 858]]\n",
      "5 10 5 10\n"
     ]
    }
   ],
   "source": [
    "# text_reader = TextReader(\"data1.txt\")\n",
    "text_reader = TextReader(\"data2.txt\",code_file=False,lower_case=True)\n",
    "window_size = 10\n",
    "X,Y = text_reader.get_X_and_Y(window_size=window_size)\n",
    "unknown_token = \"<UNK>\"\n",
    "pad_token = \"<PAD>\"\n",
    "vocab_builder = VocabBuilder(X,Y,unknown_token=unknown_token,pad_token=pad_token)\n",
    "word_to_index, index_to_word = vocab_builder.get_word_vocab(for_both=True)\n",
    "print(len(word_to_index),len(index_to_word))\n",
    "\n",
    "encoding_generator = GenerateEncoding(\n",
    "    data_x=X,data_y=Y,vocab_x=word_to_index,vocab_y=word_to_index, unknown_token=unknown_token\n",
    ")\n",
    "X_enc = encoding_generator.get_encoding_X()\n",
    "Y_enc = encoding_generator.get_encoding_Y()\n",
    "print(len(X_enc),len(Y_enc),X_enc[:4],Y_enc[:4],X_enc[-4:],Y_enc[-4:])\n",
    "\n",
    "batch_size = 5\n",
    "batch_generator = BatchGenerator(X_enc,Y_enc,batch_size)\n",
    "Xb,Yb = batch_generator.get_batch(batch_index=1)\n",
    "print(len(Xb),len(Xb[0]),len(Yb),len(Yb[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 8\n",
    "batch_generator = BatchGenerator(X_enc,Y_enc,batch_size)\n",
    "num_batches = len(X_enc)//batch_size\n",
    "embedding_dim = 50\n",
    "vocab_size = len(index_to_word)\n",
    "num_classes = len(index_to_word)\n",
    "num_lstm_layers = 4\n",
    "lstm_neurons = 100\n",
    "make_bidirectional = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before embedding layer: torch.Size([8, 10])\n",
      "After embedding layer: torch.Size([8, 10, 50])\n",
      "After lstm layer: torch.Size([8, 10, 100]) torch.Size([4, 8, 100]) torch.Size([4, 8, 100])\n",
      "After reshaping: torch.Size([80, 100])\n",
      "After 1st linear layer: torch.Size([80, 100])\n",
      "After 2nd linear layer: torch.Size([80, 953])\n",
      "torch.Size([80, 953])\n",
      "torch.Size([80, 953]) torch.Size([80])\n",
      "tensor(6.8652, grad_fn=<NllLossBackward>)\n",
      "Before embedding layer: torch.Size([8, 10])\n",
      "After embedding layer: torch.Size([8, 10, 50])\n",
      "After lstm layer: torch.Size([8, 10, 100]) torch.Size([4, 8, 100]) torch.Size([4, 8, 100])\n",
      "After reshaping: torch.Size([80, 100])\n",
      "After 1st linear layer: torch.Size([80, 100])\n",
      "After 2nd linear layer: torch.Size([80, 953])\n",
      "torch.Size([80, 953])\n",
      "torch.Size([80, 953]) torch.Size([80])\n",
      "tensor(6.2206, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = MyWordLevelRNNModel(vocab_size=vocab_size, embedding_dim=embedding_dim, lstm_neurons=lstm_neurons, \n",
    "                   num_lstm_layers=num_lstm_layers, num_classes = num_classes,\n",
    "                   make_birectional=make_bidirectional, debug_mode=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.1)\n",
    "loss_function = nn.NLLLoss()\n",
    "(ht,ct) = model.init_state_of_lstm(batch_size)\n",
    "Y_actual, Y_pred = [], []\n",
    "\n",
    "optimizer.zero_grad()\n",
    "Xb, Yb = batch_generator.get_batch(2,make_tensor=True)\n",
    "\n",
    "op, ht,ct = model(Xb,ht,ct)\n",
    "print(op.shape)\n",
    "# print(op[0])\n",
    "Yb = Yb.reshape(-1)\n",
    "print(op.shape, Yb.shape)\n",
    "loss = loss_function(op, Yb)\n",
    "print(loss)\n",
    "ht = ht.detach()\n",
    "ct = ct.detach()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "Y_pred += [int(el) for el in torch.argmax(op,axis=1)]\n",
    "Y_actual += [int(el) for el in Yb]\n",
    "\n",
    "optimizer.zero_grad()\n",
    "Xb, Yb = batch_generator.get_batch(3,make_tensor=True)\n",
    "op, ht,ct = model(Xb,ht,ct)\n",
    "print(op.shape)\n",
    "# print(op[0])\n",
    "Yb = Yb.reshape(-1)\n",
    "print(op.shape, Yb.shape)\n",
    "loss = loss_function(op, Yb)\n",
    "print(loss)\n",
    "ht = ht.detach()\n",
    "ct = ct.detach()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "Y_pred += [int(el) for el in torch.argmax(op,axis=1)]\n",
    "Y_actual += [int(el) for el in Yb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyWordLevelRNNModel(vocab_size=vocab_size, embedding_dim=embedding_dim, lstm_neurons=lstm_neurons, \n",
    "                   num_lstm_layers=num_lstm_layers, num_classes = num_classes,\n",
    "                   make_birectional=make_bidirectional, debug_mode=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "loss_function = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 1, Loss: 131.78297545015812\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 2, Loss: 126.99423511326313\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 3, Loss: 136.8924044817686\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 4, Loss: 123.07724756002426\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 5, Loss: 116.1557427495718\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 6, Loss: 100.79483003169298\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 7, Loss: 92.35524944961071\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 8, Loss: 90.00975578650832\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 9, Loss: 90.19332106783986\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 10, Loss: 91.8866440653801\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 11, Loss: 112.2954820767045\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 12, Loss: 117.11776774376631\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 13, Loss: 103.07117072492838\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 14, Loss: 76.73881471902132\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 15, Loss: 57.62259675189853\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 16, Loss: 51.86129522509873\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 17, Loss: 51.131364243105054\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 18, Loss: 61.9091759622097\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 19, Loss: 62.33991026133299\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 20, Loss: 58.316646330058575\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 21, Loss: 70.00081273540854\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 22, Loss: 81.55142200738192\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 23, Loss: 96.61030120402575\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 24, Loss: 95.60471402853727\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 25, Loss: 72.26816898025572\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 26, Loss: 65.14637525752187\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 27, Loss: 57.36174293421209\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 28, Loss: 43.30936486646533\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 29, Loss: 51.53378403466195\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 30, Loss: 50.89717826992273\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 31, Loss: 43.09038952086121\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 32, Loss: 32.74164484906942\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 33, Loss: 21.620744487270713\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 34, Loss: 19.512075544334948\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 35, Loss: 20.529464703518897\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 36, Loss: 27.09137018583715\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 37, Loss: 38.795362572185695\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 38, Loss: 59.60590658150613\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 39, Loss: 82.6634288392961\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 40, Loss: 88.39717712812126\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 41, Loss: 63.04453934542835\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 42, Loss: 37.4034351920709\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 43, Loss: 23.018711445387453\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 44, Loss: 14.638099463656545\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 45, Loss: 9.844763807719573\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 46, Loss: 7.77290373807773\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 47, Loss: 6.930555538274348\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 48, Loss: 12.438501112046652\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 49, Loss: 11.909950448200107\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 50, Loss: 23.791255209129304\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 51, Loss: 25.10718763479963\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 52, Loss: 37.28488524351269\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 53, Loss: 55.230425940826535\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 54, Loss: 65.92593692988157\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 55, Loss: 55.733024078421295\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 56, Loss: 47.71649137372151\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 57, Loss: 35.33212397340685\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 58, Loss: 19.45107964100316\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 59, Loss: 15.371808265335858\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 60, Loss: 10.184270637109876\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 61, Loss: 7.268297921051271\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 62, Loss: 5.537270600441843\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 63, Loss: 6.1207710054004565\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 64, Loss: 5.944559673429467\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 65, Loss: 8.617552083102055\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 66, Loss: 13.108774881460704\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 67, Loss: 21.36033118586056\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 68, Loss: 30.141908379271626\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 69, Loss: 38.531076348852366\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 70, Loss: 45.59557708050124\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 71, Loss: 37.67138825263828\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 72, Loss: 24.109207784291357\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 73, Loss: 16.0097919087857\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 74, Loss: 8.782968906336464\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 75, Loss: 8.049195293220691\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 76, Loss: 8.996115926187485\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 77, Loss: 7.6087358593940735\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 78, Loss: 7.648110620328225\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 79, Loss: 10.05588375206571\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 80, Loss: 10.44220484700054\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 81, Loss: 11.926891289302148\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 82, Loss: 28.393550054519437\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 83, Loss: 32.81725915707648\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 84, Loss: 44.85126982629299\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 85, Loss: 36.39891227474436\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 86, Loss: 26.01182467956096\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 87, Loss: 22.63861362275202\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 88, Loss: 10.485943637555465\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 89, Loss: 5.71467413532082\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 90, Loss: 4.070659845718183\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 91, Loss: 2.3898725685139652\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 92, Loss: 3.0572962350270245\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 93, Loss: 3.37790507558384\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 94, Loss: 4.643007851380389\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 95, Loss: 12.921066232200246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 96, Loss: 19.640829535201192\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 97, Loss: 46.16312385909259\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 98, Loss: 53.130080931354314\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 99, Loss: 32.71012499858625\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 \n",
      "Epoch: 100, Loss: 22.42812386143487\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    (ht,ct) = model.init_state_of_lstm(batch_size)\n",
    "    epoch_loss = 0\n",
    "    Y_actual, Y_pred = [], []\n",
    "    for i in range(num_batches):\n",
    "        if i%20 == 0: print(i, end=' ')\n",
    "        optimizer.zero_grad()\n",
    "        Xb, Yb = batch_generator.get_batch(i,make_tensor=True)\n",
    "        op, ht,ct = model(Xb,ht,ct)\n",
    "        Yb = Yb.reshape(-1)\n",
    "        loss = loss_function(op, Yb)\n",
    "        epoch_loss += loss.item()\n",
    "        ht = ht.detach()\n",
    "        ct = ct.detach()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"\\nEpoch: {}, Loss: {}\".format(e+1,epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11, 304, 301, 3, 636, 939, 591]]\n",
      "we believe in the power of books to help children see the world from different perspectives and build empathy. children who can empathize are able to respond to others with thoughtfulness and understanding. why is my classmate wearing a headscarf indoors? a beautiful picture book about choosing a new hijab for the first day of school can open windows. through stories, children can meet characters who are dealing with strong emotions and who learn to manage those feelings in positive ways. what a powerful model for kids, especially when they have formed a personal bond with the vividly drawn characters. some children's books tackle the tricky topic of how to handle conflicts at school or in the neighborhood. sometimes it is as simple as inviting the shy new kid to join in and play. sometimes it is about learning to find your own individual voice. and sometimes it is about learning to find 16-20 rapunzel and one that my four-year-old. give kids a chance to reflect, think about their own beliefs and social interactions, and talk with their classmates and family about thorny issues. here are some of the books we recommend for strengthening social and emotional learning. some of the books deal with bullying head-on. tim's birthday is just a logistic regression everything. or tim's here is more fit the dataset 16-20 reasoning: are she will money is tight, and tim knows his family cannot afford to buy him a board. as tim ponders how our be encouraged to think beyond themselves and celebrate the simple acts of kindness and sharing that make a difference in people's lives. our encourage is almost every day. she is six, in grade one, and will usually read 16-20 pages of one of these readers 4-5 nights per week. these stories are based on the originals e.g. rapunzel but given a quirky child-friendly twist. there are some words that our daughter will trip over on occasions, and she is at an above-average reading level for her age, but mostly they are well suited. if your child is easily frustrated by new or slightly more complex words then choose the level 2 readers. for those of you who already know how a neural network works, you should be able to find a simple structure by seeing this graph. in the next part, the activation function will be the sigmoid function. so the question is: how many does more simple regression does not linearly suited. does is: operations are new reading be the sigmoid function. so the question is: how many layers and neurons do we need in order to build a neural network you would fit the dataset above? if we use only one neuron it will be the same thing as doing a logistic regression because the activation function is the sigmoid function. and we know that it would not work because the dataset is not linearly separable, and simple logistic regression does not only is neuron for not linearly separable data. so we have to add a hidden layer. each\n"
     ]
    }
   ],
   "source": [
    "test_string = [\"we believe in the power of books\".split(\" \")]\n",
    "test_string_enc = encoding_generator.get_encoding_X(raw_text=test_string)\n",
    "pred_op = deepcopy(test_string_enc)\n",
    "print(pred_op)\n",
    "\n",
    "model.eval()\n",
    "if make_bidirectional: first_param = 2*num_lstm_layers\n",
    "else: first_param = num_lstm_layers\n",
    "ht_pred = torch.randn(first_param, 1, lstm_neurons)\n",
    "ct_pred = torch.randn(first_param, 1, lstm_neurons)\n",
    "\n",
    "unigram = True # unigram will work, becuase it is a statefulRNN (ht and ct is getting updated for every character)\n",
    "window_size = 5\n",
    "num_chars = len(test_string[0])+500\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_chars):\n",
    "        input_vec = torch.tensor([pred_op[0][i:i+1]])\n",
    "        op,ht_pred,ct_pred = model(input_vec,ht_pred,ct_pred)\n",
    "        op = torch.argmax(op,axis=1).tolist()\n",
    "        if i >= len(test_string_enc[0])-1: pred_op[0].append(op[0])\n",
    "    pred_word = \" \".join([index_to_word[el] for el in pred_op[0]])\n",
    "    print(pred_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 468, 13, 482, 429, 3, 39, 939]]\n",
      "the main unifying theme is the idea of an acts in one holds we can can man man change everything. told with honesty and respect, this timely said to my inference. is one are money is not holds as conclusion. are skateboard, he hears the can man down the street collecting throughout an reflex agent is just part of being a couple of chance encounters but encounters with the conclusion as not it situations, it as something he conclusion. but something he ways to do, but something he operate said to involve inference. for example, recoiling from a book rationally as conclusion. for more goals. we decisions. we need to be able to generate comprehensible sentences in natural language to get by in a complex society. we need learning not only for erudition, but also because it improves our ability to generate effective behavior. the rational-agent approach has ways is not all of one of several hand, all it has ways and more all one all is just is not all of one of several possible hand, correct inference is not all of one of several possible hand, correct inference is not all of one of several possible hand, correct inference is not all of one of several possible hand, first, that time successful than it for conclusion. on the laws of thought approach to ai, the emphasis was on correct inferences. making correct inferences is sometimes part of being a rational agent, because one way to act rationally is to reason logically to the conclusion that a given action will achieve oneâ€™s goals and then to act but something must still be done. there are also ways of acting rationally that cannot be said to involve inference. for example, recoiling from a hot stove is a reflex action that is usually more successful than a slower action taken after careful deliberation. all the skills needed for the turing test also allow an agent to act rationally. knowledge representation and reasoning enable agents to reach good decisions. we need to be able to generate comprehensible sentences in natural language to get because not only for erudition, but also because it improves our ability to generate effective behavior. the rational-agent approach has two advantages over the other approaches. first, it is more general our behavior. the rational-agent approach has two advantages over the other approaches. first, it is more general our behavior. the rational-agent approach has two advantages over the other approaches. first, it is more general our she our comes. our rationality. it as more than not has rather limited. leibniz did surpass pascal by building a calculator that could add, subtract, multiply, and take roots, whereas the pascaline could only add and subtract. some speculated that machines might not just do calculations but actually be able to think and act on at more only add and take has operations are calculator is speculated that not only it has wrote that just has famous. pascal wrote that the arithmetical machine produces effects which appear nearer to thought than all\n"
     ]
    }
   ],
   "source": [
    "test_string = [\"the main unifying theme is the idea of\".split(\" \")]\n",
    "test_string_enc = encoding_generator.get_encoding_X(raw_text=test_string)\n",
    "pred_op = deepcopy(test_string_enc)\n",
    "print(pred_op)\n",
    "\n",
    "model.eval()\n",
    "if make_bidirectional: first_param = 2*num_lstm_layers\n",
    "else: first_param = num_lstm_layers\n",
    "ht_pred = torch.randn(first_param, 1, lstm_neurons)\n",
    "ct_pred = torch.randn(first_param, 1, lstm_neurons)\n",
    "\n",
    "unigram = True # unigram will work, becuase it is a statefulRNN (ht and ct is getting updated for every character)\n",
    "window_size = 5\n",
    "num_chars = len(test_string[0])+500\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_chars):\n",
    "        input_vec = torch.tensor([pred_op[0][i:i+1]])\n",
    "        op,ht_pred,ct_pred = model(input_vec,ht_pred,ct_pred)\n",
    "        op = torch.argmax(op,axis=1).tolist()\n",
    "        if i >= len(test_string_enc[0])-1: pred_op[0].append(op[0])\n",
    "    pred_word = \" \".join([index_to_word[el] for el in pred_op[0]])\n",
    "    print(pred_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitf0b0a3d2859f4904a6dd3c0263fd37ec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
