{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextReader:\n",
    "    def __init__(self,filename):\n",
    "        self.filename = filename\n",
    "        \n",
    "    def get_all_words(self,regex_params=None):\n",
    "        '''\n",
    "        regex_params = {\n",
    "            \"uppercase\": True,\n",
    "            \"digits\":False,\n",
    "            \"punctuation_list\":None\n",
    "        }\n",
    "        '''\n",
    "        if regex_params:\n",
    "            regex_string = \"a-z\"\n",
    "            if regex_params[\"uppercase\"]: regex_string += \"A-Z\"\n",
    "            if regex_params[\"digits\"]: regex_string += \"0-9\"\n",
    "            if regex_params[\"punctuation_list\"]: regex_string += \"\".join(regex_params[\"punctuation_list\"])\n",
    "            regex_string = \"[\" + regex_string +\"]\"\n",
    "            with open(self.filename,\"r\") as f: text = f.read()\n",
    "            words = re.findall(regex_string,text)\n",
    "            return words\n",
    "        else:\n",
    "            with open(self.filename,\"r\") as f: words = f.read().split(\" \")\n",
    "            return words + [\" \"]\n",
    "        \n",
    "    def get_unique_words(self,regex_params=None, distinguish_casing=False):\n",
    "        '''\n",
    "        regex_params = {\n",
    "            \"uppercase\": True,\n",
    "            \"digits\":False,\n",
    "            \"punctuation_list\":None\n",
    "        }\n",
    "        '''\n",
    "        all_words = self.get_all_words(regex_params)\n",
    "        if not distinguish_casing: return list(set([word.lower() for word in all_words]))\n",
    "        else: return list(set(all_words))\n",
    "    \n",
    "    \n",
    "    def get_X_and_Y(self,window_size=10):\n",
    "        with open(self.filename,\"r\",errors=\"ignore\") as f:\n",
    "            text  = f.read()\n",
    "            X,Y = [],[]\n",
    "            for i in range(len(text)-window_size-1):\n",
    "                X.append(text[i:i+window_size])\n",
    "                Y.append(text[i+1:window_size+i+1])\n",
    "        return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabBuilder:\n",
    "    def __init__(self, words = None, sentences=None, unknown_token=\"unk\"):\n",
    "        self.unknown_token = unknown_token\n",
    "        if words:\n",
    "            self.words = words\n",
    "            self.char_to_index, self.index_to_char = self.get_char_vocab()\n",
    "        if sentences:\n",
    "            self.sentences = sentences\n",
    "            self.word_to_index, self.index_to_word = self.get_word_vocab()\n",
    "        if not words and not sentences:\n",
    "            print(\"At least 1 argument is required\")\n",
    "        \n",
    "    def get_char_vocab(self):\n",
    "        char_to_index, index_to_char = {},{}\n",
    "        all_chars = list(set(\"\".join(self.words)))\n",
    "        for i,char in enumerate(all_chars):\n",
    "            char_to_index[char] = i\n",
    "            index_to_char[i] = char\n",
    "        vocab_length = len(char_to_index)\n",
    "        char_to_index[self.unknown_token] = vocab_length\n",
    "        index_to_char[vocab_length] = self.unknown_token\n",
    "        return char_to_index, index_to_char\n",
    "    \n",
    "    def get_word_vocab(self):\n",
    "        word_to_index, index_to_word = {},{}\n",
    "        all_words = list(set(\" \".join(self.sentences.split(\" \"))))\n",
    "        for i,word in enumerate(all_words):\n",
    "            word_to_index[word] = i\n",
    "            index_to_word[i] = word\n",
    "        return word_to_index, index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateEncoding:\n",
    "    def __init__(self,data_x,vocab_x,data_y,vocab_y,unknown_token):\n",
    "        self.data_x = data_x\n",
    "        self.vocab_x = vocab_x\n",
    "        self.data_y = data_y\n",
    "        self.vocab_y = vocab_y\n",
    "        self.unknown_token = unknown_token\n",
    "        self.pure_vocab_x = self.remove_unknown_token_from_voab(vocab_x)\n",
    "        self.pure_vocab_y = self.remove_unknown_token_from_voab(vocab_y)\n",
    "    \n",
    "    def remove_unknown_token_from_voab(self,vocab):\n",
    "        return {k:v for k,v in vocab.items() if k != self.unknown_token}\n",
    "        \n",
    "    def get_encoding_X(self,raw_text=None):\n",
    "        if raw_text: data_to_encode = raw_text\n",
    "        else: data_to_encode = self.data_x\n",
    "        encoded_X = []\n",
    "        for word in data_to_encode:\n",
    "            characters = list(word)\n",
    "            word_encoding = []\n",
    "            for c in characters: \n",
    "                if c not in self.pure_vocab_x: word_encoding.append(self.vocab_x[self.unknown_token])\n",
    "                else: word_encoding.append(self.vocab_x[c])\n",
    "            encoded_X.append(word_encoding)\n",
    "        return encoded_X\n",
    "    \n",
    "    def get_encoding_Y(self,raw_text=None):\n",
    "        if raw_text: data_to_encode = raw_text\n",
    "        else: data_to_encode = self.data_y\n",
    "        encoded_Y = []\n",
    "        for word in data_to_encode:\n",
    "            characters = list(word)\n",
    "            word_encoding = []\n",
    "            for c in characters: \n",
    "                if c not in self.pure_vocab_y: word_encoding.append(self.vocab_y[self.unknown_token])\n",
    "                else: word_encoding.append(self.vocab_y[c])\n",
    "            encoded_Y.append(word_encoding)\n",
    "        return encoded_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self,X,Y,batch_size):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def get_batch(self,batch_index,make_tensor=False):\n",
    "        Xb = self.X[batch_index*self.batch_size:(batch_index+1)*self.batch_size]\n",
    "        Yb = self.Y[batch_index*self.batch_size:(batch_index+1)*self.batch_size]\n",
    "        if make_tensor: return torch.tensor(Xb),torch.tensor(Yb)\n",
    "        return Xb,Yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCharLevelRNNModel(nn.Module):\n",
    "    def __init__(self,vocab_size, embedding_dim, lstm_neurons, num_lstm_layers, num_classes,\n",
    "                 make_birectional=False, debug_mode=False):\n",
    "        super().__init__()\n",
    "        self.debug_mode = debug_mode\n",
    "        self.bidirectional = make_birectional\n",
    "        self.lstm_neurons = lstm_neurons\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=lstm_neurons, \n",
    "                            num_layers=num_lstm_layers, bidirectional=make_birectional, batch_first=True)\n",
    "        \n",
    "        in_features = lstm_neurons\n",
    "        if self.bidirectional: in_features = 2*lstm_neurons\n",
    "        self.linear1 = nn.Linear(in_features=in_features, out_features=100)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(in_features=100, out_features=num_classes)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self,x,ht,ct):\n",
    "        if self.debug_mode: print(\"Before embedding layer:\",x.shape)\n",
    "        x = self.embedding(x)\n",
    "        if self.debug_mode: print(\"After embedding layer:\",x.shape)\n",
    "        x, (ht, ct) = self.lstm(x,(ht,ct))\n",
    "        if self.debug_mode: print(\"After lstm layer:\",x.shape,ht.shape,ct.shape)\n",
    "        x = x.reshape(-1, x.shape[2])\n",
    "        if self.debug_mode: print(\"After reshaping:\",x.shape)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        if self.debug_mode: print(\"After 1st linear layer:\",x.shape)\n",
    "        x = self.linear2(x)\n",
    "        x = self.log_softmax(x)\n",
    "        if self.debug_mode: print(\"After 2nd linear layer:\",x.shape)\n",
    "        return x, ht,ct\n",
    "    \n",
    "    def init_state_of_lstm(self,batch_size):\n",
    "        if self.bidirectional: first_param = 2*self.num_lstm_layers\n",
    "        else: first_param = self.num_lstm_layers\n",
    "        return (\n",
    "            torch.randn(first_param, batch_size, self.lstm_neurons),\n",
    "            torch.randn(first_param, batch_size, self.lstm_neurons),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "12854 12854 ['At Reading R', 't Reading Ro', ' Reading Roc', 'Reading Rock'] ['t Reading Ro', ' Reading Roc', 'Reading Rock', 'eading Rocke'] [' relevant to', 'relevant tod', 'elevant toda', 'levant today'] ['relevant tod', 'elevant toda', 'levant today', 'evant today.']\n",
      "12854 12854 [[42, 75, 49, 40, 3, 23, 9, 63, 54, 35, 49, 40], [75, 49, 40, 3, 23, 9, 63, 54, 35, 49, 40, 39], [49, 40, 3, 23, 9, 63, 54, 35, 49, 40, 39, 32], [40, 3, 23, 9, 63, 54, 35, 49, 40, 39, 32, 26]] [[75, 49, 40, 3, 23, 9, 63, 54, 35, 49, 40, 39], [49, 40, 3, 23, 9, 63, 54, 35, 49, 40, 39, 32], [40, 3, 23, 9, 63, 54, 35, 49, 40, 39, 32, 26], [3, 23, 9, 63, 54, 35, 49, 40, 39, 32, 26, 3]] [[49, 65, 3, 2, 3, 0, 23, 54, 75, 49, 75, 39], [65, 3, 2, 3, 0, 23, 54, 75, 49, 75, 39, 9], [3, 2, 3, 0, 23, 54, 75, 49, 75, 39, 9, 23], [2, 3, 0, 23, 54, 75, 49, 75, 39, 9, 23, 25]] [[65, 3, 2, 3, 0, 23, 54, 75, 49, 75, 39, 9], [3, 2, 3, 0, 23, 54, 75, 49, 75, 39, 9, 23], [2, 3, 0, 23, 54, 75, 49, 75, 39, 9, 23, 25], [3, 0, 23, 54, 75, 49, 75, 39, 9, 23, 25, 18]]\n",
      "5 12 5 12\n"
     ]
    }
   ],
   "source": [
    "text_reader = TextReader(\"data2.txt\")\n",
    "# all_words = text_reader.get_all_words(regex_params={\n",
    "#     \"uppercase\":True,\"digits\":True,\"punctuation_list\":[\" \",\".\",\",\",\"'\",\";\",\"\\-\",\"?\",\"!\",\"\\[\",\"\\]\",\"{\",\"}\",\"(\",\")\"]\n",
    "# })\n",
    "all_words = text_reader.get_all_words(regex_params=None)\n",
    "window_size = 12\n",
    "X,Y = text_reader.get_X_and_Y(window_size=window_size)\n",
    "vocab_builder = VocabBuilder(words=all_words,unknown_token=\"unk\")\n",
    "char_to_index, index_to_char = vocab_builder.char_to_index, vocab_builder.index_to_char\n",
    "print(len(char_to_index))\n",
    "\n",
    "encoding_generator = GenerateEncoding(X,char_to_index,Y,char_to_index,unknown_token=\"unk\")\n",
    "X_enc = encoding_generator.get_encoding_X()\n",
    "Y_enc = encoding_generator.get_encoding_Y()\n",
    "print(len(X),len(Y),X[:4],Y[:4],X[-4:],Y[-4:])\n",
    "print(len(X_enc),len(Y_enc),X_enc[:4],Y_enc[:4],X_enc[-4:],Y_enc[-4:])\n",
    "\n",
    "batch_size = 5\n",
    "batch_generator = BatchGenerator(X_enc,Y_enc,batch_size)\n",
    "Xb,Yb = batch_generator.get_batch(batch_index=1)\n",
    "print(len(Xb),len(Xb[0]),len(Yb),len(Yb[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "batch_generator = BatchGenerator(X_enc,Y_enc,batch_size)\n",
    "num_batches = len(X_enc)//batch_size\n",
    "embedding_dim = 3\n",
    "vocab_size = len(index_to_char)\n",
    "num_classes = len(index_to_char)\n",
    "num_lstm_layers = 2\n",
    "lstm_neurons = 128\n",
    "make_bidirectional = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before embedding layer: torch.Size([32, 12])\n",
      "After embedding layer: torch.Size([32, 12, 3])\n",
      "After lstm layer: torch.Size([32, 12, 128]) torch.Size([2, 32, 128]) torch.Size([2, 32, 128])\n",
      "After reshaping: torch.Size([384, 128])\n",
      "After 1st linear layer: torch.Size([384, 100])\n",
      "After 2nd linear layer: torch.Size([384, 77])\n",
      "torch.Size([384, 77])\n",
      "tensor([-4.4361, -4.3294, -4.2114, -4.2545, -4.3792, -4.3892, -4.4505, -4.3554,\n",
      "        -4.3625, -4.3226, -4.3423, -4.3603, -4.3385, -4.4103, -4.3496, -4.2818,\n",
      "        -4.4174, -4.3350, -4.3268, -4.2208, -4.2867, -4.2928, -4.4521, -4.2276,\n",
      "        -4.2879, -4.2412, -4.4175, -4.4062, -4.3712, -4.4885, -4.3801, -4.2676,\n",
      "        -4.4052, -4.4136, -4.3674, -4.4011, -4.3821, -4.3810, -4.3118, -4.4981,\n",
      "        -4.1939, -4.4214, -4.3237, -4.3946, -4.4105, -4.3398, -4.4227, -4.2411,\n",
      "        -4.2748, -4.4929, -4.2987, -4.3210, -4.2568, -4.3841, -4.3083, -4.4307,\n",
      "        -4.3511, -4.2583, -4.2456, -4.3684, -4.3079, -4.1747, -4.4052, -4.3565,\n",
      "        -4.3175, -4.2485, -4.3230, -4.4084, -4.4264, -4.4027, -4.3947, -4.4504,\n",
      "        -4.2627, -4.1888, -4.3837, -4.4031, -4.3426], grad_fn=<SelectBackward>)\n",
      "torch.Size([384, 77]) torch.Size([384])\n",
      "tensor(4.3503, grad_fn=<NllLossBackward>)\n",
      "Before embedding layer: torch.Size([32, 12])\n",
      "After embedding layer: torch.Size([32, 12, 3])\n",
      "After lstm layer: torch.Size([32, 12, 128]) torch.Size([2, 32, 128]) torch.Size([2, 32, 128])\n",
      "After reshaping: torch.Size([384, 128])\n",
      "After 1st linear layer: torch.Size([384, 100])\n",
      "After 2nd linear layer: torch.Size([384, 77])\n",
      "torch.Size([384, 77])\n",
      "tensor([-6.1408, -6.0394, -3.2575, -2.1895, -5.9258, -5.8491, -6.3097, -6.0757,\n",
      "        -5.9599, -2.6943, -6.1172, -3.3664, -6.1413, -6.1126, -5.8179, -5.9634,\n",
      "        -6.2923, -5.9956, -6.2546, -5.9541, -5.8096, -3.2624, -3.3946, -5.9455,\n",
      "        -6.1292, -5.9773, -6.0611, -6.1706, -3.2243, -6.1636, -6.0232, -6.0829,\n",
      "        -6.0601, -6.2988, -6.2064, -5.9950, -6.2156, -5.8818, -6.0733, -2.9422,\n",
      "        -5.8345, -6.1701, -5.8960, -6.2994, -6.0557, -6.0344, -6.2773, -3.9857,\n",
      "        -6.3754, -2.5136, -6.0294, -6.0475, -6.0415, -6.0125, -2.9165, -6.1138,\n",
      "        -2.5854, -5.5437, -5.8603, -5.9245, -5.9470, -5.7788, -5.9657, -3.1815,\n",
      "        -6.0706, -2.2732, -5.7250, -6.0880, -5.8612, -6.1935, -5.9697, -6.0337,\n",
      "        -5.7363, -5.8454, -5.9427, -2.8455, -6.0129], grad_fn=<SelectBackward>)\n",
      "torch.Size([384, 77]) torch.Size([384])\n",
      "tensor(4.1386, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = MyCharLevelRNNModel(vocab_size=vocab_size, embedding_dim=embedding_dim, lstm_neurons=lstm_neurons, \n",
    "                   num_lstm_layers=num_lstm_layers, num_classes = num_classes,\n",
    "                   make_birectional=make_bidirectional, debug_mode=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.1)\n",
    "loss_function = nn.NLLLoss()\n",
    "(ht,ct) = model.init_state_of_lstm(batch_size)\n",
    "Y_actual, Y_pred = [], []\n",
    "\n",
    "optimizer.zero_grad()\n",
    "Xb, Yb = batch_generator.get_batch(2,make_tensor=True)\n",
    "\n",
    "op, ht,ct = model(Xb,ht,ct)\n",
    "print(op.shape)\n",
    "print(op[0])\n",
    "Yb = Yb.reshape(-1)\n",
    "print(op.shape, Yb.shape)\n",
    "loss = loss_function(op, Yb)\n",
    "print(loss)\n",
    "ht = ht.detach()\n",
    "ct = ct.detach()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "Y_pred += [int(el) for el in torch.argmax(op,axis=1)]\n",
    "Y_actual += [int(el) for el in Yb]\n",
    "\n",
    "optimizer.zero_grad()\n",
    "Xb, Yb = batch_generator.get_batch(3,make_tensor=True)\n",
    "op, ht,ct = model(Xb,ht,ct)\n",
    "print(op.shape)\n",
    "print(op[0])\n",
    "Yb = Yb.reshape(-1)\n",
    "print(op.shape, Yb.shape)\n",
    "loss = loss_function(op, Yb)\n",
    "print(loss)\n",
    "ht = ht.detach()\n",
    "ct = ct.detach()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "Y_pred += [int(el) for el in torch.argmax(op,axis=1)]\n",
    "Y_actual += [int(el) for el in Yb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyCharLevelRNNModel(vocab_size=vocab_size, embedding_dim=embedding_dim, lstm_neurons=lstm_neurons, \n",
    "                   num_lstm_layers=num_lstm_layers, num_classes = num_classes,\n",
    "                   make_birectional=make_bidirectional, debug_mode=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "loss_function = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 1, Loss: 469.7949805855751\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 2, Loss: 475.5837924480438\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 3, Loss: 471.34292113780975\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 4, Loss: 464.0449299812317\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 5, Loss: 462.09237909317017\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 6, Loss: 458.13329952955246\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 7, Loss: 459.25620913505554\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 8, Loss: 455.44268375635147\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 9, Loss: 455.67768996953964\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 10, Loss: 448.5609117746353\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 11, Loss: 450.01674085855484\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 12, Loss: 449.13132506608963\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 13, Loss: 446.9939349889755\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 14, Loss: 455.0220409631729\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 15, Loss: 447.72018855810165\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 16, Loss: 446.3360763788223\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 17, Loss: 441.3556032180786\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 18, Loss: 443.87227696180344\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 19, Loss: 441.7523113489151\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 20, Loss: 438.98260432481766\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 21, Loss: 439.5410150885582\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 22, Loss: 439.98730820417404\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 23, Loss: 440.78847765922546\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 24, Loss: 442.72450935840607\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 25, Loss: 441.5580030679703\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 26, Loss: 433.77345192432404\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 27, Loss: 430.14452987909317\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 28, Loss: 426.1813297867775\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 29, Loss: 430.5139464735985\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 30, Loss: 431.6603690981865\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 31, Loss: 431.2231085896492\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 32, Loss: 430.8401094675064\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 33, Loss: 428.74174535274506\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 34, Loss: 428.2868656516075\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 35, Loss: 429.8115693330765\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 36, Loss: 421.9481455683708\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 37, Loss: 413.9588943719864\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 38, Loss: 418.24553793668747\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 39, Loss: 418.3415118455887\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 40, Loss: 423.17955154180527\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 41, Loss: 418.08724468946457\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 42, Loss: 412.2075899839401\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 43, Loss: 409.85233068466187\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 44, Loss: 414.72368305921555\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 45, Loss: 414.9772325158119\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 46, Loss: 419.2665722966194\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 47, Loss: 413.2816758751869\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 48, Loss: 408.74729657173157\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 49, Loss: 407.1069722175598\n",
      "0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 \n",
      "Epoch: 50, Loss: 410.3383932709694\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    (ht,ct) = model.init_state_of_lstm(batch_size)\n",
    "    epoch_loss = 0\n",
    "    Y_actual, Y_pred = [], []\n",
    "    for i in range(num_batches):\n",
    "        if i%20 == 0: print(i, end=' ')\n",
    "        optimizer.zero_grad()\n",
    "        Xb, Yb = batch_generator.get_batch(i,make_tensor=True)\n",
    "        op, ht,ct = model(Xb,ht,ct)\n",
    "        Yb = Yb.reshape(-1)\n",
    "        loss = loss_function(op, Yb)\n",
    "        epoch_loss += loss.item()\n",
    "        ht = ht.detach()\n",
    "        ct = ct.detach()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"\\nEpoch: {}, Loss: {}\".format(e+1,epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47, 17, 65, 32, 11, 23, 21, 3, 49, 23, 49, 21, 26]]\n",
      "purchase a skateboard, he and the program was also designed to accept new axioms in the program was also designed \n"
     ]
    }
   ],
   "source": [
    "test_string = [\"purchase a sk\"]\n",
    "test_string_enc = encoding_generator.get_encoding_X(raw_text=test_string)\n",
    "pred_op = deepcopy(test_string_enc)\n",
    "print(pred_op)\n",
    "\n",
    "model.eval()\n",
    "if make_bidirectional: first_param = 2*num_lstm_layers\n",
    "else: first_param = num_lstm_layers\n",
    "ht_pred = torch.randn(first_param, 1, lstm_neurons)\n",
    "ct_pred = torch.randn(first_param, 1, lstm_neurons)\n",
    "\n",
    "unigram = True # unigram will work, becuase it is a statefulRNN (ht and ct is getting updated for every character)\n",
    "window_size = 5\n",
    "num_chars = len(test_string[0])+100\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_chars):\n",
    "        input_vec = torch.tensor([pred_op[0][i:i+1]])\n",
    "        op,ht_pred,ct_pred = model(input_vec,ht_pred,ct_pred)\n",
    "        op = torch.argmax(op,axis=1).tolist()\n",
    "        if i >= len(test_string_enc[0])-1: pred_op[0].append(op[0])\n",
    "    pred_word = \"\".join([index_to_char[el] for el in pred_op[0]])\n",
    "    print(pred_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitf0b0a3d2859f4904a6dd3c0263fd37ec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
