{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6704 6704\n"
     ]
    }
   ],
   "source": [
    "title_lemma,desc_lemma = [],[]\n",
    "with open(\"title_lemma.txt\",\"r\") as f:\n",
    "    for line in f:\n",
    "        title_lemma.append(line.strip().split(\" \"))\n",
    "with open(\"desc_lemma.txt\",\"r\") as f:\n",
    "    for line in f:\n",
    "        desc_lemma.append(line.strip().split(\" \"))\n",
    "print(len(title_lemma),len(desc_lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_corpus = title_lemma + desc_lemma\n",
    "# model = Word2Vec(doc_corpus, min_count=1,size=100,window=3,workers=32,sg=0,iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_glove = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_glove: \n",
    "    word2vec_file = 'pre_trained_glove_100d.txt'\n",
    "    model = KeyedVectors.load_word2vec_format(word2vec_file, binary=False)\n",
    "else:\n",
    "    model = Word2Vec.load('modelW2V_100iter.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vec_matrix(model,sentence,number_of_words):\n",
    "    not_found_words = []\n",
    "    if len(sentence) < number_of_words:\n",
    "        sentence = sentence + [\".\"]*(number_of_words - len(sentence))\n",
    "    else:\n",
    "        sentence = sentence[:number_of_words]\n",
    "    data_point = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            data_point.append(model.wv[word])\n",
    "        except:\n",
    "            not_found_words.append(word)\n",
    "            data_point.append(model.wv['.'])\n",
    "    return not_found_words,data_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6704 6704 6704 1 ['']\n",
      "0.6539379474940334\n"
     ]
    }
   ],
   "source": [
    "X,y,documents = [],[],[]\n",
    "not_found_words = []\n",
    "for title,desc in zip(title_lemma,desc_lemma):\n",
    "    doc = title + desc\n",
    "    not_found_words_in_doc, data_point = get_word_vec_matrix(model,doc,60)\n",
    "    not_found_words += not_found_words_in_doc\n",
    "    documents.append(doc)\n",
    "    X.append(data_point)\n",
    "with open(\"rating.txt\",\"r\") as f:\n",
    "    for line in f:\n",
    "        y.append(int(line.strip()))\n",
    "print(len(X),len(y),len(documents),len(not_found_words),not_found_words[:10])\n",
    "print(sum(y)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val, doc_tr, doc_val = train_test_split(X,y,documents,test_size=0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671, 6033, 60)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val),len(X_tr),len(X_tr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6534062655395325 0.6587183308494784\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_tr)/len(y_tr), sum(y_val)/len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLoader:\n",
    "    def __init__(self,X,y,batch_size):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def get_batch(self,batch_index):\n",
    "        X = torch.tensor(self.X[batch_index*self.batch_size:(batch_index+1)*self.batch_size],dtype=torch.float)\n",
    "        X = X.reshape(batch_size,100,60)\n",
    "        y = torch.tensor(self.y[batch_index*self.batch_size:(batch_index+1)*self.batch_size])\n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_epochs = 20\n",
    "batch_size = 1000\n",
    "no_of_batches = int(len(X_tr)/batch_size)\n",
    "device = torch.device(\"cuda:0\")\n",
    "text_loader = TextLoader(X_tr,y_tr,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 100, 60]) torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "Xb, yb = text_loader.get_batch(1)\n",
    "print(Xb.shape,yb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModelLinear(nn.Module):\n",
    "    def __init__(self, debug_mode=False):\n",
    "        super().__init__()\n",
    "        self.debug = debug_mode   \n",
    "        self.selu = nn.SELU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(in_features=100*60, out_features=100)\n",
    "        self.linear2 = nn.Linear(in_features=100, out_features=2)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        if self.debug: print(\"ip\",x.shape)\n",
    "  \n",
    "        x = self.flatten(x)\n",
    "        if self.debug: print(\"flattened_op\",x.shape)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        if self.debug: print('l1_z',x.shape)\n",
    "        x = self.selu(x)\n",
    "        if self.debug: print('l1_a',x.shape)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "        if self.debug: print('l2_z',x.shape)\n",
    "        x = self.log_softmax(x)\n",
    "        if self.debug: print('l2_a',x.shape)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TextClassificationModelLinear(debug_mode=True)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip torch.Size([1000, 100, 60])\n",
      "flattened_op torch.Size([1000, 6000])\n",
      "l1_z torch.Size([1000, 100])\n",
      "l1_a torch.Size([1000, 100])\n",
      "l2_z torch.Size([1000, 2])\n",
      "l2_a torch.Size([1000, 2])\n",
      "Accuracy: 0.642\n"
     ]
    }
   ],
   "source": [
    "Xb,yb = text_loader.get_batch(0)\n",
    "op = classifier(Xb)\n",
    "y_pred = torch.argmax(op,axis=1)\n",
    "count = 0\n",
    "for el1,el2 in zip(y_pred,yb): \n",
    "    if el1 == el2: count += 1\n",
    "print(\"Accuracy:\",count/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = torch.tensor(X_val,dtype=torch.float).reshape(671,100,60)\n",
    "def get_val_score(model):\n",
    "    y_op = model(X_val)\n",
    "    y_pred = torch.argmax(y_op,axis=1)\n",
    "    count = 0\n",
    "    for el1,el2 in zip(y_pred,y_val):\n",
    "        if el1 == el2: count += 1\n",
    "    print(\"Validation accuracy:\",count/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TextClassificationModelLinear(debug_mode=False)\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 0 Loss: 0.7506355047225952 Batch Accuracy: 0.451\n",
      "Epoch: 0 Batch: 1 Loss: 11.182941436767578 Batch Accuracy: 0.658\n",
      "Epoch: 0 Batch: 2 Loss: 8.07805061340332 Batch Accuracy: 0.633\n",
      "Epoch: 0 Batch: 3 Loss: 2.410994052886963 Batch Accuracy: 0.622\n",
      "Epoch: 0 Batch: 4 Loss: 1.7781628370285034 Batch Accuracy: 0.358\n",
      "Epoch: 0 Batch: 5 Loss: 1.853316068649292 Batch Accuracy: 0.319\n",
      "Validation accuracy: 0.35469448584202684\n",
      "Epoch: 1 Batch: 0 Loss: 0.9905802607536316 Batch Accuracy: 0.342\n",
      "Epoch: 1 Batch: 1 Loss: 0.6540819406509399 Batch Accuracy: 0.658\n",
      "Epoch: 1 Batch: 2 Loss: 0.8795104026794434 Batch Accuracy: 0.633\n",
      "Epoch: 1 Batch: 3 Loss: 1.102521538734436 Batch Accuracy: 0.622\n",
      "Epoch: 1 Batch: 4 Loss: 1.115944504737854 Batch Accuracy: 0.655\n",
      "Epoch: 1 Batch: 5 Loss: 1.029209852218628 Batch Accuracy: 0.682\n",
      "Validation accuracy: 0.6572280178837556\n",
      "Epoch: 2 Batch: 0 Loss: 1.0175026655197144 Batch Accuracy: 0.67\n",
      "Epoch: 2 Batch: 1 Loss: 0.949316143989563 Batch Accuracy: 0.658\n",
      "Epoch: 2 Batch: 2 Loss: 0.8775784969329834 Batch Accuracy: 0.633\n",
      "Epoch: 2 Batch: 3 Loss: 0.7462604641914368 Batch Accuracy: 0.622\n",
      "Epoch: 2 Batch: 4 Loss: 0.5983233451843262 Batch Accuracy: 0.655\n",
      "Epoch: 2 Batch: 5 Loss: 0.5791934728622437 Batch Accuracy: 0.763\n",
      "Validation accuracy: 0.5350223546944859\n",
      "Epoch: 3 Batch: 0 Loss: 0.6624202132225037 Batch Accuracy: 0.541\n",
      "Epoch: 3 Batch: 1 Loss: 0.7277402281761169 Batch Accuracy: 0.436\n",
      "Epoch: 3 Batch: 2 Loss: 0.7303224205970764 Batch Accuracy: 0.457\n",
      "Epoch: 3 Batch: 3 Loss: 0.6872569918632507 Batch Accuracy: 0.522\n",
      "Epoch: 3 Batch: 4 Loss: 0.6061127781867981 Batch Accuracy: 0.621\n",
      "Epoch: 3 Batch: 5 Loss: 0.5514474511146545 Batch Accuracy: 0.767\n",
      "Validation accuracy: 0.7928464977645305\n",
      "Epoch: 4 Batch: 0 Loss: 0.5191686153411865 Batch Accuracy: 0.807\n",
      "Epoch: 4 Batch: 1 Loss: 0.5328040719032288 Batch Accuracy: 0.723\n",
      "Epoch: 4 Batch: 2 Loss: 0.5836129784584045 Batch Accuracy: 0.642\n",
      "Epoch: 4 Batch: 3 Loss: 0.6260260939598083 Batch Accuracy: 0.628\n",
      "Epoch: 4 Batch: 4 Loss: 0.5755651593208313 Batch Accuracy: 0.657\n",
      "Epoch: 4 Batch: 5 Loss: 0.5460832118988037 Batch Accuracy: 0.692\n",
      "Validation accuracy: 0.6915052160953801\n",
      "Epoch: 5 Batch: 0 Loss: 0.5188873410224915 Batch Accuracy: 0.71\n",
      "Epoch: 5 Batch: 1 Loss: 0.503213107585907 Batch Accuracy: 0.784\n",
      "Epoch: 5 Batch: 2 Loss: 0.49242183566093445 Batch Accuracy: 0.805\n",
      "Epoch: 5 Batch: 3 Loss: 0.4849209487438202 Batch Accuracy: 0.805\n",
      "Epoch: 5 Batch: 4 Loss: 0.44932666420936584 Batch Accuracy: 0.805\n",
      "Epoch: 5 Batch: 5 Loss: 0.4608142673969269 Batch Accuracy: 0.783\n",
      "Validation accuracy: 0.7839046199701938\n",
      "Epoch: 6 Batch: 0 Loss: 0.4546058773994446 Batch Accuracy: 0.798\n",
      "Epoch: 6 Batch: 1 Loss: 0.44087716937065125 Batch Accuracy: 0.798\n",
      "Epoch: 6 Batch: 2 Loss: 0.41641467809677124 Batch Accuracy: 0.823\n",
      "Epoch: 6 Batch: 3 Loss: 0.4020688831806183 Batch Accuracy: 0.821\n",
      "Epoch: 6 Batch: 4 Loss: 0.36849287152290344 Batch Accuracy: 0.843\n",
      "Epoch: 6 Batch: 5 Loss: 0.35129687190055847 Batch Accuracy: 0.86\n",
      "Validation accuracy: 0.8405365126676602\n",
      "Epoch: 7 Batch: 0 Loss: 0.34419146180152893 Batch Accuracy: 0.849\n",
      "Epoch: 7 Batch: 1 Loss: 0.3281280994415283 Batch Accuracy: 0.848\n",
      "Epoch: 7 Batch: 2 Loss: 0.3400120139122009 Batch Accuracy: 0.856\n",
      "Epoch: 7 Batch: 3 Loss: 0.3321431875228882 Batch Accuracy: 0.854\n",
      "Epoch: 7 Batch: 4 Loss: 0.3283950984477997 Batch Accuracy: 0.868\n",
      "Epoch: 7 Batch: 5 Loss: 0.30854278802871704 Batch Accuracy: 0.871\n",
      "Validation accuracy: 0.8688524590163934\n",
      "Epoch: 8 Batch: 0 Loss: 0.3193734884262085 Batch Accuracy: 0.868\n",
      "Epoch: 8 Batch: 1 Loss: 0.3128822445869446 Batch Accuracy: 0.855\n",
      "Epoch: 8 Batch: 2 Loss: 0.3045045733451843 Batch Accuracy: 0.873\n",
      "Epoch: 8 Batch: 3 Loss: 0.29992547631263733 Batch Accuracy: 0.876\n",
      "Epoch: 8 Batch: 4 Loss: 0.30563223361968994 Batch Accuracy: 0.878\n",
      "Epoch: 8 Batch: 5 Loss: 0.2772945165634155 Batch Accuracy: 0.885\n",
      "Validation accuracy: 0.8822652757078987\n",
      "Epoch: 9 Batch: 0 Loss: 0.26992249488830566 Batch Accuracy: 0.884\n",
      "Epoch: 9 Batch: 1 Loss: 0.2542162239551544 Batch Accuracy: 0.885\n",
      "Epoch: 9 Batch: 2 Loss: 0.2631676495075226 Batch Accuracy: 0.888\n",
      "Epoch: 9 Batch: 3 Loss: 0.26466861367225647 Batch Accuracy: 0.888\n",
      "Epoch: 9 Batch: 4 Loss: 0.2523728311061859 Batch Accuracy: 0.895\n",
      "Epoch: 9 Batch: 5 Loss: 0.24603897333145142 Batch Accuracy: 0.892\n",
      "Validation accuracy: 0.879284649776453\n",
      "Epoch: 10 Batch: 0 Loss: 0.24040567874908447 Batch Accuracy: 0.907\n",
      "Epoch: 10 Batch: 1 Loss: 0.23359550535678864 Batch Accuracy: 0.897\n",
      "Epoch: 10 Batch: 2 Loss: 0.23755687475204468 Batch Accuracy: 0.903\n",
      "Epoch: 10 Batch: 3 Loss: 0.2421824187040329 Batch Accuracy: 0.899\n",
      "Epoch: 10 Batch: 4 Loss: 0.2225816398859024 Batch Accuracy: 0.912\n",
      "Epoch: 10 Batch: 5 Loss: 0.2090962678194046 Batch Accuracy: 0.919\n",
      "Validation accuracy: 0.8837555886736215\n",
      "Epoch: 11 Batch: 0 Loss: 0.20703449845314026 Batch Accuracy: 0.928\n",
      "Epoch: 11 Batch: 1 Loss: 0.2063979208469391 Batch Accuracy: 0.913\n",
      "Epoch: 11 Batch: 2 Loss: 0.20216158032417297 Batch Accuracy: 0.93\n",
      "Epoch: 11 Batch: 3 Loss: 0.2075730562210083 Batch Accuracy: 0.924\n",
      "Epoch: 11 Batch: 4 Loss: 0.19643546640872955 Batch Accuracy: 0.925\n",
      "Epoch: 11 Batch: 5 Loss: 0.18254505097866058 Batch Accuracy: 0.939\n",
      "Validation accuracy: 0.8837555886736215\n",
      "Epoch: 12 Batch: 0 Loss: 0.18257758021354675 Batch Accuracy: 0.943\n",
      "Epoch: 12 Batch: 1 Loss: 0.17751502990722656 Batch Accuracy: 0.932\n",
      "Epoch: 12 Batch: 2 Loss: 0.1762305647134781 Batch Accuracy: 0.933\n",
      "Epoch: 12 Batch: 3 Loss: 0.18090926110744476 Batch Accuracy: 0.944\n",
      "Epoch: 12 Batch: 4 Loss: 0.17007245123386383 Batch Accuracy: 0.945\n",
      "Epoch: 12 Batch: 5 Loss: 0.1610652506351471 Batch Accuracy: 0.95\n",
      "Validation accuracy: 0.8882265275707899\n",
      "Epoch: 13 Batch: 0 Loss: 0.1621827483177185 Batch Accuracy: 0.949\n",
      "Epoch: 13 Batch: 1 Loss: 0.15661540627479553 Batch Accuracy: 0.945\n",
      "Epoch: 13 Batch: 2 Loss: 0.14891663193702698 Batch Accuracy: 0.95\n",
      "Epoch: 13 Batch: 3 Loss: 0.15958751738071442 Batch Accuracy: 0.952\n",
      "Epoch: 13 Batch: 4 Loss: 0.14732183516025543 Batch Accuracy: 0.954\n",
      "Epoch: 13 Batch: 5 Loss: 0.1379198580980301 Batch Accuracy: 0.966\n",
      "Validation accuracy: 0.8912071535022354\n",
      "Epoch: 14 Batch: 0 Loss: 0.13980883359909058 Batch Accuracy: 0.958\n",
      "Epoch: 14 Batch: 1 Loss: 0.13584870100021362 Batch Accuracy: 0.955\n",
      "Epoch: 14 Batch: 2 Loss: 0.1220104843378067 Batch Accuracy: 0.967\n",
      "Epoch: 14 Batch: 3 Loss: 0.13406363129615784 Batch Accuracy: 0.96\n",
      "Epoch: 14 Batch: 4 Loss: 0.12804155051708221 Batch Accuracy: 0.959\n",
      "Epoch: 14 Batch: 5 Loss: 0.1193966269493103 Batch Accuracy: 0.972\n",
      "Validation accuracy: 0.8941877794336811\n",
      "Epoch: 15 Batch: 0 Loss: 0.11834047734737396 Batch Accuracy: 0.966\n",
      "Epoch: 15 Batch: 1 Loss: 0.11473287642002106 Batch Accuracy: 0.964\n",
      "Epoch: 15 Batch: 2 Loss: 0.10106315463781357 Batch Accuracy: 0.976\n",
      "Epoch: 15 Batch: 3 Loss: 0.11347591131925583 Batch Accuracy: 0.969\n",
      "Epoch: 15 Batch: 4 Loss: 0.1071457490324974 Batch Accuracy: 0.971\n",
      "Epoch: 15 Batch: 5 Loss: 0.10385681688785553 Batch Accuracy: 0.978\n",
      "Validation accuracy: 0.8971684053651267\n",
      "Epoch: 16 Batch: 0 Loss: 0.10064514726400375 Batch Accuracy: 0.977\n",
      "Epoch: 16 Batch: 1 Loss: 0.09698633849620819 Batch Accuracy: 0.973\n",
      "Epoch: 16 Batch: 2 Loss: 0.08380964398384094 Batch Accuracy: 0.982\n",
      "Epoch: 16 Batch: 3 Loss: 0.09679315984249115 Batch Accuracy: 0.974\n",
      "Epoch: 16 Batch: 4 Loss: 0.09034884721040726 Batch Accuracy: 0.978\n",
      "Epoch: 16 Batch: 5 Loss: 0.08939730376005173 Batch Accuracy: 0.98\n",
      "Validation accuracy: 0.8956780923994039\n",
      "Epoch: 17 Batch: 0 Loss: 0.08469704538583755 Batch Accuracy: 0.983\n",
      "Epoch: 17 Batch: 1 Loss: 0.08118103444576263 Batch Accuracy: 0.98\n",
      "Epoch: 17 Batch: 2 Loss: 0.06922028213739395 Batch Accuracy: 0.99\n",
      "Epoch: 17 Batch: 3 Loss: 0.0822736918926239 Batch Accuracy: 0.982\n",
      "Epoch: 17 Batch: 4 Loss: 0.0759938508272171 Batch Accuracy: 0.982\n",
      "Epoch: 17 Batch: 5 Loss: 0.07634585350751877 Batch Accuracy: 0.984\n",
      "Validation accuracy: 0.8897168405365127\n",
      "Epoch: 18 Batch: 0 Loss: 0.07125551253557205 Batch Accuracy: 0.986\n",
      "Epoch: 18 Batch: 1 Loss: 0.06789282709360123 Batch Accuracy: 0.986\n",
      "Epoch: 18 Batch: 2 Loss: 0.05751035735011101 Batch Accuracy: 0.992\n",
      "Epoch: 18 Batch: 3 Loss: 0.0695558488368988 Batch Accuracy: 0.987\n",
      "Epoch: 18 Batch: 4 Loss: 0.06270450353622437 Batch Accuracy: 0.99\n",
      "Epoch: 18 Batch: 5 Loss: 0.06509817391633987 Batch Accuracy: 0.987\n",
      "Validation accuracy: 0.8897168405365127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 Batch: 0 Loss: 0.060349270701408386 Batch Accuracy: 0.988\n",
      "Epoch: 19 Batch: 1 Loss: 0.056859225034713745 Batch Accuracy: 0.989\n",
      "Epoch: 19 Batch: 2 Loss: 0.047608040273189545 Batch Accuracy: 0.995\n",
      "Epoch: 19 Batch: 3 Loss: 0.058458585292100906 Batch Accuracy: 0.989\n",
      "Epoch: 19 Batch: 4 Loss: 0.052664000540971756 Batch Accuracy: 0.992\n",
      "Epoch: 19 Batch: 5 Loss: 0.05518941953778267 Batch Accuracy: 0.99\n",
      "Validation accuracy: 0.8926974664679582\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(no_of_epochs):\n",
    "    for i in range(no_of_batches):\n",
    "        optimizer.zero_grad()\n",
    "        Xb,yb = text_loader.get_batch(i)\n",
    "        op = classifier(Xb)\n",
    "        loss = loss_fn(op,yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_pred = torch.argmax(op,axis=1)\n",
    "        count = 0\n",
    "        for el1,el2 in zip(y_pred,yb): \n",
    "            if el1 == el2: count += 1\n",
    "        print(\"Epoch:\",epoch,\"Batch:\",i,\"Loss:\",loss.item(),\"Batch Accuracy:\",count/len(y_pred))\n",
    "    get_val_score(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "my_review = \"i am so waiting to visit the hotel again\".strip().split(\" \")\n",
    "not_found_words,data_point = get_word_vec_matrix(model,my_review,60)\n",
    "print(not_found_words)\n",
    "data_point = torch.tensor(data_point,dtype=torch.float).reshape(1,100,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_op = classifier(data_point)\n",
    "y_pred = torch.argmax(my_op,axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModelConv(nn.Module):\n",
    "    def __init__(self, debug_mode=False):\n",
    "        super().__init__()\n",
    "        self.debug = debug_mode\n",
    "        self.conv1 = nn.Conv1d(in_channels=100, kernel_size=3,out_channels=120)  \n",
    "        self.conv2 = nn.Conv1d(in_channels=120, kernel_size=3,out_channels=240)\n",
    "        self.conv3 = nn.Conv1d(in_channels=240, kernel_size=3,out_channels=480) \n",
    "        self.selu = nn.SELU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=56)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(in_features=240*1, out_features=50)\n",
    "        self.linear2 = nn.Linear(in_features=50, out_features=2)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        if self.debug: print(\"ip\",x.shape)\n",
    "            \n",
    "#         1st conv layer      \n",
    "        x = self.conv1(x)\n",
    "        if self.debug: print('conv1_op',x.shape)\n",
    "        x = self.selu(x)\n",
    "        if self.debug: print('selu_op',x.shape)\n",
    "#         x = self.maxpool(x)\n",
    "#         if self.debug: print('pool1_op',x.shape)\n",
    "\n",
    "#         2nd conv layer      \n",
    "        x = self.conv2(x)\n",
    "        if self.debug: print('conv2_op',x.shape)\n",
    "        x = self.selu(x)\n",
    "        if self.debug: print('selu_op',x.shape)\n",
    "        x = self.maxpool(x)\n",
    "        if self.debug: print('pool2_op',x.shape)\n",
    "\n",
    "# #         3rd conv layer      \n",
    "#         x = self.conv3(x)\n",
    "#         if self.debug: print('conv3_op',x.shape)\n",
    "#         x = self.selu(x)\n",
    "#         if self.debug: print('selu_op',x.shape)\n",
    "# #         x = self.maxpool(x)\n",
    "# #         if self.debug: print('pool1_op',x.shape)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        if self.debug: print(\"flattened_op\",x.shape)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        if self.debug: print('l1_z',x.shape)\n",
    "        x = self.selu(x)\n",
    "        if self.debug: print('l1_a',x.shape)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "        if self.debug: print('l2_z',x.shape)\n",
    "        x = self.log_softmax(x)\n",
    "        if self.debug: print('l2_a',x.shape)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip torch.Size([1000, 100, 60])\n",
      "conv1_op torch.Size([1000, 120, 58])\n",
      "selu_op torch.Size([1000, 120, 58])\n",
      "conv2_op torch.Size([1000, 240, 56])\n",
      "selu_op torch.Size([1000, 240, 56])\n",
      "pool2_op torch.Size([1000, 240, 1])\n",
      "flattened_op torch.Size([1000, 240])\n",
      "l1_z torch.Size([1000, 50])\n",
      "l1_a torch.Size([1000, 50])\n",
      "l2_z torch.Size([1000, 2])\n",
      "l2_a torch.Size([1000, 2])\n",
      "Accuracy: 0.584\n"
     ]
    }
   ],
   "source": [
    "classifier_conv = TextClassificationModelConv(debug_mode=True)\n",
    "Xb,yb = text_loader.get_batch(0)\n",
    "op = classifier_conv(Xb)\n",
    "y_pred = torch.argmax(op,axis=1)\n",
    "count = 0\n",
    "for el1,el2 in zip(y_pred,yb): \n",
    "    if el1 == el2: count += 1\n",
    "print(\"Accuracy:\",count/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_conv = TextClassificationModelConv(debug_mode=False)\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(classifier_conv.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 0 Loss: 0.7320619225502014 Batch Accuracy: 0.334\n",
      "Epoch: 0 Batch: 1 Loss: 3.9010252952575684 Batch Accuracy: 0.657\n",
      "Epoch: 0 Batch: 2 Loss: 2.1872470378875732 Batch Accuracy: 0.633\n",
      "Epoch: 0 Batch: 3 Loss: 0.746225118637085 Batch Accuracy: 0.622\n",
      "Epoch: 0 Batch: 4 Loss: 1.6548269987106323 Batch Accuracy: 0.344\n",
      "Epoch: 0 Batch: 5 Loss: 1.1714307069778442 Batch Accuracy: 0.318\n",
      "Validation accuracy: 0.40536512667660207\n",
      "Epoch: 1 Batch: 0 Loss: 0.7045931220054626 Batch Accuracy: 0.405\n",
      "Epoch: 1 Batch: 1 Loss: 0.6449160575866699 Batch Accuracy: 0.657\n",
      "Epoch: 1 Batch: 2 Loss: 0.7529591917991638 Batch Accuracy: 0.633\n",
      "Epoch: 1 Batch: 3 Loss: 0.8573747873306274 Batch Accuracy: 0.622\n",
      "Epoch: 1 Batch: 4 Loss: 0.7753465175628662 Batch Accuracy: 0.656\n",
      "Epoch: 1 Batch: 5 Loss: 0.6709977388381958 Batch Accuracy: 0.682\n",
      "Validation accuracy: 0.6572280178837556\n",
      "Epoch: 2 Batch: 0 Loss: 0.6443325877189636 Batch Accuracy: 0.671\n",
      "Epoch: 2 Batch: 1 Loss: 0.637850284576416 Batch Accuracy: 0.66\n",
      "Epoch: 2 Batch: 2 Loss: 0.6688176989555359 Batch Accuracy: 0.628\n",
      "Epoch: 2 Batch: 3 Loss: 0.676618218421936 Batch Accuracy: 0.607\n",
      "Epoch: 2 Batch: 4 Loss: 0.6314658522605896 Batch Accuracy: 0.669\n",
      "Epoch: 2 Batch: 5 Loss: 0.6167392730712891 Batch Accuracy: 0.684\n",
      "Validation accuracy: 0.6497764530551415\n",
      "Epoch: 3 Batch: 0 Loss: 0.62270188331604 Batch Accuracy: 0.683\n",
      "Epoch: 3 Batch: 1 Loss: 0.6185920834541321 Batch Accuracy: 0.664\n",
      "Epoch: 3 Batch: 2 Loss: 0.623075544834137 Batch Accuracy: 0.663\n",
      "Epoch: 3 Batch: 3 Loss: 0.6254987716674805 Batch Accuracy: 0.693\n",
      "Epoch: 3 Batch: 4 Loss: 0.5586248636245728 Batch Accuracy: 0.703\n",
      "Epoch: 3 Batch: 5 Loss: 0.540477454662323 Batch Accuracy: 0.72\n",
      "Validation accuracy: 0.7287630402384501\n",
      "Epoch: 4 Batch: 0 Loss: 0.4891751706600189 Batch Accuracy: 0.775\n",
      "Epoch: 4 Batch: 1 Loss: 0.5261436700820923 Batch Accuracy: 0.74\n",
      "Epoch: 4 Batch: 2 Loss: 0.5366113185882568 Batch Accuracy: 0.737\n",
      "Epoch: 4 Batch: 3 Loss: 0.4803583025932312 Batch Accuracy: 0.771\n",
      "Epoch: 4 Batch: 4 Loss: 0.5851215720176697 Batch Accuracy: 0.701\n",
      "Epoch: 4 Batch: 5 Loss: 0.5670052170753479 Batch Accuracy: 0.749\n",
      "Validation accuracy: 0.713859910581222\n",
      "Epoch: 5 Batch: 0 Loss: 0.5974419116973877 Batch Accuracy: 0.728\n",
      "Epoch: 5 Batch: 1 Loss: 0.40169012546539307 Batch Accuracy: 0.823\n",
      "Epoch: 5 Batch: 2 Loss: 0.6013625860214233 Batch Accuracy: 0.693\n",
      "Epoch: 5 Batch: 3 Loss: 0.43626856803894043 Batch Accuracy: 0.823\n",
      "Epoch: 5 Batch: 4 Loss: 0.4476543664932251 Batch Accuracy: 0.783\n",
      "Epoch: 5 Batch: 5 Loss: 0.4501637816429138 Batch Accuracy: 0.78\n",
      "Validation accuracy: 0.797317436661699\n",
      "Epoch: 6 Batch: 0 Loss: 0.39153409004211426 Batch Accuracy: 0.827\n",
      "Epoch: 6 Batch: 1 Loss: 0.3745788633823395 Batch Accuracy: 0.836\n",
      "Epoch: 6 Batch: 2 Loss: 0.3994731605052948 Batch Accuracy: 0.829\n",
      "Epoch: 6 Batch: 3 Loss: 0.3902530074119568 Batch Accuracy: 0.83\n",
      "Epoch: 6 Batch: 4 Loss: 0.3653043508529663 Batch Accuracy: 0.843\n",
      "Epoch: 6 Batch: 5 Loss: 0.3673449158668518 Batch Accuracy: 0.85\n",
      "Validation accuracy: 0.8360655737704918\n",
      "Epoch: 7 Batch: 0 Loss: 0.3397396504878998 Batch Accuracy: 0.857\n",
      "Epoch: 7 Batch: 1 Loss: 0.3202487826347351 Batch Accuracy: 0.877\n",
      "Epoch: 7 Batch: 2 Loss: 0.3153381049633026 Batch Accuracy: 0.875\n",
      "Epoch: 7 Batch: 3 Loss: 0.31866395473480225 Batch Accuracy: 0.857\n",
      "Epoch: 7 Batch: 4 Loss: 0.32123178243637085 Batch Accuracy: 0.859\n",
      "Epoch: 7 Batch: 5 Loss: 0.30132216215133667 Batch Accuracy: 0.883\n",
      "Validation accuracy: 0.8435171385991058\n",
      "Epoch: 8 Batch: 0 Loss: 0.2957446575164795 Batch Accuracy: 0.883\n",
      "Epoch: 8 Batch: 1 Loss: 0.2694327235221863 Batch Accuracy: 0.902\n",
      "Epoch: 8 Batch: 2 Loss: 0.2710345983505249 Batch Accuracy: 0.892\n",
      "Epoch: 8 Batch: 3 Loss: 0.2844088673591614 Batch Accuracy: 0.875\n",
      "Epoch: 8 Batch: 4 Loss: 0.28144371509552 Batch Accuracy: 0.881\n",
      "Epoch: 8 Batch: 5 Loss: 0.2660157084465027 Batch Accuracy: 0.903\n",
      "Validation accuracy: 0.8450074515648286\n",
      "Epoch: 9 Batch: 0 Loss: 0.26214224100112915 Batch Accuracy: 0.906\n",
      "Epoch: 9 Batch: 1 Loss: 0.23325476050376892 Batch Accuracy: 0.918\n",
      "Epoch: 9 Batch: 2 Loss: 0.23346243798732758 Batch Accuracy: 0.913\n",
      "Epoch: 9 Batch: 3 Loss: 0.2932862937450409 Batch Accuracy: 0.874\n",
      "Epoch: 9 Batch: 4 Loss: 0.31271296739578247 Batch Accuracy: 0.879\n",
      "Epoch: 9 Batch: 5 Loss: 0.22418159246444702 Batch Accuracy: 0.92\n",
      "Validation accuracy: 0.8256333830104322\n",
      "Epoch: 10 Batch: 0 Loss: 0.2596619129180908 Batch Accuracy: 0.898\n",
      "Epoch: 10 Batch: 1 Loss: 0.27055972814559937 Batch Accuracy: 0.89\n",
      "Epoch: 10 Batch: 2 Loss: 0.20051395893096924 Batch Accuracy: 0.929\n",
      "Epoch: 10 Batch: 3 Loss: 0.3929937183856964 Batch Accuracy: 0.812\n",
      "Epoch: 10 Batch: 4 Loss: 0.3230747878551483 Batch Accuracy: 0.863\n",
      "Epoch: 10 Batch: 5 Loss: 0.32872533798217773 Batch Accuracy: 0.856\n",
      "Validation accuracy: 0.8390461997019374\n",
      "Epoch: 11 Batch: 0 Loss: 0.23292504251003265 Batch Accuracy: 0.913\n",
      "Epoch: 11 Batch: 1 Loss: 0.33950716257095337 Batch Accuracy: 0.847\n",
      "Epoch: 11 Batch: 2 Loss: 0.29360222816467285 Batch Accuracy: 0.862\n",
      "Epoch: 11 Batch: 3 Loss: 0.376787006855011 Batch Accuracy: 0.832\n",
      "Epoch: 11 Batch: 4 Loss: 0.2747515141963959 Batch Accuracy: 0.878\n",
      "Epoch: 11 Batch: 5 Loss: 0.2792355418205261 Batch Accuracy: 0.896\n",
      "Validation accuracy: 0.8390461997019374\n",
      "Epoch: 12 Batch: 0 Loss: 0.2369241565465927 Batch Accuracy: 0.892\n",
      "Epoch: 12 Batch: 1 Loss: 0.2680043876171112 Batch Accuracy: 0.884\n",
      "Epoch: 12 Batch: 2 Loss: 0.18549734354019165 Batch Accuracy: 0.932\n",
      "Epoch: 12 Batch: 3 Loss: 0.21450845897197723 Batch Accuracy: 0.925\n",
      "Epoch: 12 Batch: 4 Loss: 0.3093419373035431 Batch Accuracy: 0.856\n",
      "Epoch: 12 Batch: 5 Loss: 0.20576034486293793 Batch Accuracy: 0.923\n",
      "Validation accuracy: 0.8077496274217586\n",
      "Epoch: 13 Batch: 0 Loss: 0.35792413353919983 Batch Accuracy: 0.856\n",
      "Epoch: 13 Batch: 1 Loss: 0.19539043307304382 Batch Accuracy: 0.93\n",
      "Epoch: 13 Batch: 2 Loss: 0.22879350185394287 Batch Accuracy: 0.892\n",
      "Epoch: 13 Batch: 3 Loss: 0.18609164655208588 Batch Accuracy: 0.932\n",
      "Epoch: 13 Batch: 4 Loss: 0.14502853155136108 Batch Accuracy: 0.956\n",
      "Epoch: 13 Batch: 5 Loss: 0.16630448400974274 Batch Accuracy: 0.95\n",
      "Validation accuracy: 0.8509687034277198\n",
      "Epoch: 14 Batch: 0 Loss: 0.1663891226053238 Batch Accuracy: 0.943\n",
      "Epoch: 14 Batch: 1 Loss: 0.15049071609973907 Batch Accuracy: 0.948\n",
      "Epoch: 14 Batch: 2 Loss: 0.12377595156431198 Batch Accuracy: 0.96\n",
      "Epoch: 14 Batch: 3 Loss: 0.13081783056259155 Batch Accuracy: 0.956\n",
      "Epoch: 14 Batch: 4 Loss: 0.14124105870723724 Batch Accuracy: 0.952\n",
      "Epoch: 14 Batch: 5 Loss: 0.13357079029083252 Batch Accuracy: 0.96\n",
      "Validation accuracy: 0.8405365126676602\n",
      "Epoch: 15 Batch: 0 Loss: 0.17708107829093933 Batch Accuracy: 0.938\n",
      "Epoch: 15 Batch: 1 Loss: 0.15110161900520325 Batch Accuracy: 0.951\n",
      "Epoch: 15 Batch: 2 Loss: 0.09478737413883209 Batch Accuracy: 0.97\n",
      "Epoch: 15 Batch: 3 Loss: 0.14495784044265747 Batch Accuracy: 0.951\n",
      "Epoch: 15 Batch: 4 Loss: 0.08952201157808304 Batch Accuracy: 0.976\n",
      "Epoch: 15 Batch: 5 Loss: 0.11011302471160889 Batch Accuracy: 0.971\n",
      "Validation accuracy: 0.849478390461997\n",
      "Epoch: 16 Batch: 0 Loss: 0.10207211971282959 Batch Accuracy: 0.972\n",
      "Epoch: 16 Batch: 1 Loss: 0.09900402277708054 Batch Accuracy: 0.973\n",
      "Epoch: 16 Batch: 2 Loss: 0.08657314628362656 Batch Accuracy: 0.968\n",
      "Epoch: 16 Batch: 3 Loss: 0.07954075187444687 Batch Accuracy: 0.981\n",
      "Epoch: 16 Batch: 4 Loss: 0.18652622401714325 Batch Accuracy: 0.912\n",
      "Epoch: 16 Batch: 5 Loss: 0.24875394999980927 Batch Accuracy: 0.897\n",
      "Validation accuracy: 0.8286140089418778\n",
      "Epoch: 17 Batch: 0 Loss: 0.17379678785800934 Batch Accuracy: 0.935\n",
      "Epoch: 17 Batch: 1 Loss: 0.18328753113746643 Batch Accuracy: 0.924\n",
      "Epoch: 17 Batch: 2 Loss: 0.08329219371080399 Batch Accuracy: 0.97\n",
      "Epoch: 17 Batch: 3 Loss: 0.15161888301372528 Batch Accuracy: 0.939\n",
      "Epoch: 17 Batch: 4 Loss: 0.11245036870241165 Batch Accuracy: 0.962\n",
      "Epoch: 17 Batch: 5 Loss: 0.1919146180152893 Batch Accuracy: 0.926\n",
      "Validation accuracy: 0.8077496274217586\n",
      "Epoch: 18 Batch: 0 Loss: 0.2002398520708084 Batch Accuracy: 0.917\n",
      "Epoch: 18 Batch: 1 Loss: 0.2614412307739258 Batch Accuracy: 0.877\n",
      "Epoch: 18 Batch: 2 Loss: 0.1165376827120781 Batch Accuracy: 0.963\n",
      "Epoch: 18 Batch: 3 Loss: 0.24567627906799316 Batch Accuracy: 0.9\n",
      "Epoch: 18 Batch: 4 Loss: 0.15145249664783478 Batch Accuracy: 0.928\n",
      "Epoch: 18 Batch: 5 Loss: 0.13065043091773987 Batch Accuracy: 0.961\n",
      "Validation accuracy: 0.8435171385991058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 Batch: 0 Loss: 0.10712306946516037 Batch Accuracy: 0.964\n",
      "Epoch: 19 Batch: 1 Loss: 0.08305250108242035 Batch Accuracy: 0.976\n",
      "Epoch: 19 Batch: 2 Loss: 0.07678007334470749 Batch Accuracy: 0.976\n",
      "Epoch: 19 Batch: 3 Loss: 0.06640906631946564 Batch Accuracy: 0.982\n",
      "Epoch: 19 Batch: 4 Loss: 0.08200797438621521 Batch Accuracy: 0.97\n",
      "Epoch: 19 Batch: 5 Loss: 0.0782724991440773 Batch Accuracy: 0.976\n",
      "Validation accuracy: 0.8479880774962743\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(no_of_epochs):\n",
    "    for i in range(no_of_batches):\n",
    "        optimizer.zero_grad()\n",
    "        Xb,yb = text_loader.get_batch(i)\n",
    "        op = classifier_conv(Xb)\n",
    "        loss = loss_fn(op,yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_pred = torch.argmax(op,axis=1)\n",
    "        count = 0\n",
    "        for el1,el2 in zip(y_pred,yb): \n",
    "            if el1 == el2: count += 1\n",
    "        print(\"Epoch:\",epoch,\"Batch:\",i,\"Loss:\",loss.item(),\"Batch Accuracy:\",count/len(y_pred))\n",
    "    get_val_score(classifier_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_review = \"i dislike the hotel\".strip().split(\" \")\n",
    "not_found_words,data_point = get_word_vec_matrix(model,my_review,60)\n",
    "print(not_found_words)\n",
    "data_point = torch.tensor(data_point,dtype=torch.float).reshape(1,100,60)\n",
    "my_op = classifier_conv(data_point)\n",
    "y_pred = torch.argmax(my_op,axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitf0b0a3d2859f4904a6dd3c0263fd37ec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
